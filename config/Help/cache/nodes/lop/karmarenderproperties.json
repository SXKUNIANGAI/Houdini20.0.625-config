{"type": "root", "attrs": {"type": "node", "context": "lop", "internal": "karmarenderproperties", "icon": "LOP/karmarenderproperties", "since": "18.0", "tags": "rendering,karma", "version": null, "namespace": null}, "body": [{"level": 0, "type": "title", "indent": 0, "text": ["Karma Render Properties"], "extent": [130, 158]}, {"type": "summary", "indent": 0, "text": ["Configure Render Properties for Karma."], "extent": [158, 205]}, {"type": "para", "indent": 0, "text": ["The Karma Render Properties LOP creates ", {"scheme": "Node", "value": "/nodes/lop/rendervar", "type": "link", "text": ["render vars"], "fullpath": "/nodes/lop/rendervar.html"}, ", a ", {"scheme": "Node", "value": "/nodes/lop/renderproduct", "type": "link", "text": ["render product"], "fullpath": "/nodes/lop/renderproduct.html"}, " and a ", {"scheme": "Node", "value": "/nodes/lop/rendersettings", "type": "link", "text": ["render settings"], "fullpath": "/nodes/lop/rendersettings.html"}, " primitive, configured for Karma."], "extent": [205, 403]}, {"level": 1, "id": "parameters", "container": true, "type": "parameters_section", "indent": 0, "role": "section", "extent": [403, 415], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Rendersettings Primitive Path"], "extent": [597, 628], "body": [{"type": "para", "indent": 4, "text": ["This node creates a ", {"type": "code", "text": ["RenderSettings"]}, " prim with the configuration you set up using the parameters. This is the scene tree path where this node will create the ", {"type": "code", "text": ["RenderSettings"]}, " prim."], "extent": [647, 833]}], "container": true, "attrs": {"id": "primpath"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Output Picture"], "extent": [833, 849], "body": [{"type": "para", "indent": 4, "text": ["An output image filename (usually an ", {"type": "code", "text": [".EXR"]}, " file), or ", {"type": "code", "text": ["ip"]}, " which renders the image in MPlay."], "extent": [867, 969]}, {"type": "para", "indent": 4, "text": ["Include ", {"type": "code", "text": ["$F"]}, " in the file name to insert the frame number. This is necessary when rendering animation. See ", {"scheme": null, "value": "/render/expressions", "type": "link", "text": ["expressions in file names"], "fullpath": "/render/expressions.html"}, " for more information."], "extent": [969, 1150]}], "container": true, "attrs": {"id": "picture"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Camera"], "extent": [1745, 1757], "body": [{"type": "para", "indent": 8, "text": ["Path to a USD camera (", {"type": "code", "text": ["UsdGeomCamera"]}, ") prim to render the scene from."], "extent": [1778, 1857]}], "container": true, "attrs": {"id": "camera"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Resolution Mode"], "extent": [1857, 1878], "body": [{"type": "para", "indent": 8, "text": ["Use the USD Camera\u2019s aperture aspect ratio to automatically set one dimension of the resolution."], "extent": [1901, 2007]}, {"type": "para", "indent": 8, "text": ["The computed parm is set using an expression, but is locked to prevent accidental edits."], "extent": [2007, 2105]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 8, "text": ["Manual"], "extent": [2105, 2121], "body": [{"type": "para", "indent": 12, "text": ["Set the resolution height and width values."], "extent": [2121, 2178]}], "container": true}, {"type": "dt", "indent": 8, "text": ["Set Width, Compute Height from Aperture"], "extent": [2178, 2227], "body": [{"type": "para", "indent": 12, "text": ["Set the width size, while height is computed from the width and the camera aspect ratio."], "extent": [2227, 2329]}], "container": true}, {"type": "dt", "indent": 8, "text": ["Set Height, Compute Width from Aperture"], "extent": [2329, 2378], "body": [{"type": "para", "indent": 12, "text": ["Set the height size, while width is computed from the width and the camera aspect ratio."], "extent": [2378, 2480]}], "container": true}], "container": true}], "container": true, "attrs": {"id": "res_mode"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Resolution"], "extent": [2480, 2496], "body": [{"type": "para", "indent": 8, "text": ["The horizontal and vertical size of the output image, in pixels."], "extent": [2521, 2595]}], "container": true, "attrs": {"id": "resolution"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Rendering Engine"], "extent": [1255, 1273], "body": [{"type": "para", "indent": 4, "text": ["Select the rendering engine."], "extent": [2872, 2906]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": ["CPU"], "extent": [2906, 2915], "body": [{"type": "para", "indent": 8, "text": ["Runs entirely on the CPU. Since this engine is entirely in software, it will ", {"type": "em", "text": ["generally"]}, " have more features and more correct output, however it is much slower than the ", {"scheme": null, "value": "/solaris/karma_xpu", "type": "link", "text": ["XPU engine"], "fullpath": "/solaris/karma_xpu.html"}, "."], "extent": [2915, 3125]}], "container": true}, {"type": "dt", "indent": 4, "text": ["XPU"], "extent": [3125, 3134], "body": [{"type": "para", "indent": 8, "text": ["The ", {"scheme": null, "value": "/solaris/karma_xpu", "type": "link", "text": ["XPU engine"], "fullpath": "/solaris/karma_xpu.html"}, " uses available CPU and GPU (graphics card hardware) resources. Since this engine inherits the limits of what can be done on a GPU, it will ", {"type": "em", "text": ["generally"]}, " lag behind the CPU engine in features, however it is much faster than the CPU engine."], "extent": [3134, 3416]}], "container": true}], "container": true}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Simplified Shading"], "extent": [1331, 1351], "body": [{"type": "para", "indent": 4, "text": ["Disable all shading and lighting (render with one headlight on the camera). This might be useful for preview purposes if a shaded view is too slow to render."], "extent": [1377, 1540]}], "container": true, "attrs": {"id": "force_headlight"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Primary Samples"], "extent": [1540, 1557], "body": [{"type": "para", "indent": 4, "text": ["The number of ray-samples sent through each pixel. More samples will result in a less noisy image. ", {"type": "q", "text": []}, "Pixel Samples", {"type": "q", "text": [" and "]}, "Primary Samples\" are the same."], "extent": [14585, 14742]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}, {"level": 2, "id": "rendering_tab", "container": true, "type": "h", "indent": 0, "text": ["Rendering"], "extent": [1624, 1656], "body": [{"level": 3, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Sampling"], "extent": [1656, 1678], "body": [{"level": 3, "type": "sep", "indent": 4, "text": [" Secondary "], "extent": [1678, 1701]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Min Secondary Samples"], "extent": [1701, 1729], "body": [{"type": "para", "indent": 4, "text": ["Minimum number of rays to cast in per-component variance anti-aliasing."], "extent": [67978, 68055]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Max Secondary Samples"], "extent": [1806, 1833], "body": [{"type": "para", "indent": 4, "text": ["Maximum number of rays to cast in per-component variance anti-aliasing."], "extent": [68152, 68229]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}, {"level": 3, "type": "sep", "indent": 4, "text": [" Indirect Samples Quality "], "extent": [1910, 1947]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Diffuse Quality"], "extent": [1947, 1969], "body": [{"type": "para", "indent": 4, "text": ["This parameter acts as a multiplier on ", {"type": "ui", "text": ["Min Secondary Samples"]}, " and ", {"type": "ui", "text": ["Max Secondary Samples"]}, " for indirect diffuse component."], "extent": [57745, 57877]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Reflection Quality"], "extent": [2039, 2063], "body": [{"type": "para", "indent": 4, "text": ["This parameter acts as a multiplier on ", {"type": "ui", "text": ["Min Secondary Samples"]}, " and ", {"type": "ui", "text": ["Max Secondary Samples"]}, " for indirect reflect component."], "extent": [57963, 58095]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Refraction Quality"], "extent": [2133, 2157], "body": [{"type": "para", "indent": 4, "text": ["This parameter acts as a multiplier on ", {"type": "ui", "text": ["Min Secondary Samples"]}, " and ", {"type": "ui", "text": ["Max Secondary Samples"]}, " for indirect refract component."], "extent": [58181, 58313]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Volume Quality"], "extent": [2227, 2247], "body": [{"type": "para", "indent": 4, "text": ["This parameter acts as a multiplier on ", {"type": "ui", "text": ["Min Secondary Samples"]}, " and ", {"type": "ui", "text": ["Max Secondary Samples"]}, " for indirect volume component."], "extent": [58394, 58525]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["SSS Quality"], "extent": [2316, 2333], "body": [{"type": "para", "indent": 4, "text": ["This parameter acts as a multiplier on ", {"type": "ui", "text": ["Min Secondary Samples"]}, " and ", {"type": "ui", "text": ["Max Secondary Samples"]}, " for the SSS component."], "extent": [58600, 58723]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}, {"level": 3, "type": "sep", "indent": 4, "text": [" Lights Quality "], "extent": [2403, 2430]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Light Sampling Mode"], "extent": [2430, 2456], "body": [{"type": "para", "indent": 4, "text": ["Whether Karma should perform uniform sampling of lights or whether\n    rendering should use the light tree. The light tree can be significantly\n    faster for scenes that have large numbers of lights."], "extent": [16005, 16211]}, {"type": "para", "indent": 4, "text": ["Some lights cannot be added to the light tree, and will all be sampled by Karma:"], "extent": [16211, 16297]}, {"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["Dome Lights"], "extent": [16297, 16315]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["Distant Lights"], "extent": [16315, 16336]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["Point Lights"], "extent": [16336, 16355]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["Lights with Light Filters"], "extent": [16355, 16387]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["Lights with shaping controls (i.e. spot lights)"], "extent": [16387, 16442]}], "container": true}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Light Sampling Quality"], "extent": [2531, 2559], "body": [{"type": "para", "indent": 4, "text": ["This is a global control to improve sampling quality for all lights. This\n    acts as a multiplier on the individual light quality controls.  Increasing\n    the quality will improve direct light sampling as well as\n    shadows/occlusion."], "extent": [16540, 16783]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}, {"level": 3, "type": "sep", "indent": 4, "text": [" Volumes and Opacity "], "extent": [2637, 2669]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Screendoor Samples"], "extent": [2669, 2694], "body": [{"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/sampling/VolumeSamplingStochastic.jpg", "type": "img", "text": ""}], "role": "item", "extent": [15457, 15532]}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["The number of transparent samples to be shaded as a ray travels through\n    partially opaque objects. Increasing this value will result in less noise\n    in partially opaque objects and is generally less costly than increasing\n    Pixel samples, Volume Step Rate, or Min and Max ray samples. This parameter\n    will not have any effect on noise from Indirect Sources however."], "extent": [15532, 15913]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Volume Step Rate"], "extent": [2765, 2787], "body": [{"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/sampling_tab/VolumeQuality.jpg", "type": "img", "text": ""}], "role": "item", "extent": [58807, 58875]}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["How finely or coarsely a volume is sampled as a ray travels through it.\n    Volumetric objects are made up of 3-dimensional structures called Voxels, the\n    value of this parameter represents the number of voxels a ray will\n    travel through before performing another sample."], "extent": [58875, 59158]}, {"type": "para", "indent": 4, "text": ["The default value is ", {"type": "code", "text": ["0.25"]}, ", which means that every one of every four\n    voxels will be sampled. A value of ", {"type": "code", "text": ["1"]}, " means that all voxels are\n    sampled and a value of ", {"type": "code", "text": ["2"]}, " means that all voxels are sampled twice. This\n    means that the volume step rate value behaves in a similar way to pixel\n    samples, acting as a multiplier on the total number of samples for\n    volumetric objects."], "extent": [59158, 59550]}, {"type": "para", "indent": 4, "text": ["Keep in mind that increasing the volume step rate can dramatically increase\n    render times, so it should only be adjusted when necessary. Also, while\n    increasing the default from ", {"type": "code", "text": ["0.25"]}, " can reduce volumetric noise, increasing\n    the value beyond ", {"type": "code", "text": ["1"]}, " will rarely see similar results."], "extent": [59550, 59844]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 3, "id": "limits_tab", "container": true, "type": "h", "indent": 4, "text": ["Limits"], "extent": [2857, 2889], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Diffuse Limt"], "extent": [2889, 2908], "body": [{"type": "para", "indent": 4, "text": ["The number of times diffuse rays can propagate through your scene."], "extent": [51972, 52044]}, {"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/limits_tab/DiffuseLimit.jpg", "type": "img", "text": ""}], "role": "item", "extent": [52044, 52109]}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["Unlike ", {"type": "ui", "text": ["Reflect Limit"]}, " and ", {"type": "ui", "text": ["Refract Limit"]}, ", this parameter will increase the overall amount of light in your scene and contribute to the majority of global illumination. With this parameter set to values greater than ", {"type": "code", "text": ["0"]}, ", diffuse surfaces will accumulate light from other objects in addition to direct light sources."], "extent": [52109, 52435]}, {"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/limits_tab/DiffuseLimitCompare.jpg", "type": "img", "text": ""}], "role": "item", "extent": [52435, 52507]}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["In this example, increasing the ", {"type": "ui", "text": ["Diffuse Limit"]}, " has a dramatic effect on the appearance of the final image. To replicate realistic lighting conditions, it is often necessary to increase the ", {"type": "ui", "text": ["Diffuse Limit"]}, ". However, since the amount of light contribution usually decreases with each diffuse bounce, increasing the ", {"type": "ui", "text": ["Diffuse Limit"]}, " beyond ", {"type": "code", "text": ["4"]}, " hardly improve the visual fidelity of a scene. Additionally, increasing the ", {"type": "ui", "text": ["Diffuse Limit"]}, " can dramatically increase noise levels and render times."], "extent": [52507, 53010]}, {"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/limits_tab/DiffuseSubtleCompare.jpg", "type": "img", "text": ""}], "role": "item", "extent": [53010, 53083]}], "container": true, "role": "item_group"}, {"type": "box_group", "body": [{"ext": null, "type": "box", "indent": 4, "role": "item", "extent": [53083, 53093], "body": [{"type": "para", "indent": 8, "text": ["This is a float because all limits are stochastically picked per-sample, so for example you can set the diffuse limit to ", {"type": "code", "text": ["3.25"]}, " and have 25% of the rays with a diffuse limit of ", {"type": "code", "text": ["4"]}, " and 75% of rays with a diffuse limit of ", {"type": "code", "text": ["3"]}, "."], "extent": [53125, 53360]}], "container": true, "attrs": {"id": "stochastic_limits"}}], "container": true, "role": "item_group"}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Reflection Limit"], "extent": [2976, 2998], "body": [], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Refraction Limit"], "extent": [3067, 3089], "body": [{"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/limits_tab/RefractLimit.jpg", "type": "img", "text": ""}], "role": "item", "extent": [54608, 54673], "body": [{"type": "para", "indent": 8, "text": ["This parameter control the number of times a ray be refracted in your scene."], "extent": [54673, 54759]}], "container": true}, {"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/limits_tab/RefractSceneSetup.png", "type": "img", "text": ""}], "role": "item", "extent": [54759, 54829], "body": [{"type": "para", "indent": 8, "text": ["This example shows a simple scene with ten grids all in a row."], "extent": [54829, 54901]}], "container": true}, {"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/limits_tab/RefractLimitCompare.jpg", "type": "img", "text": ""}], "role": "item", "extent": [54901, 54973], "body": [{"type": "para", "indent": 8, "text": ["By applying a refractive shader, we will be able see through the grids to an image of a sunset in the background."], "extent": [54973, 55096]}], "container": true}, {"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/limits_tab/RefractSubtleCompare.jpg", "type": "img", "text": ""}], "role": "item", "extent": [55096, 55169], "body": [{"type": "para", "indent": 8, "text": ["From this camera angle, in order for the image to be accurate, the refraction limit must match the number of grids that that are in the scene. However, most scenes will not have this number of refractive objects all in a row and so it is possible to reduce the refract limit without affecting the final image while also reducing the time it takes to render them."], "extent": [55169, 55541]}], "container": true}, {"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/limits_tab/RefractLimitSurfaces.jpg", "type": "img", "text": ""}], "role": "item", "extent": [55541, 55614], "body": [{"type": "para", "indent": 8, "text": ["Keep in mind that this ", {"type": "ui", "text": ["Refract Limit"]}, " refers to the number of surfaces that the ray must travel through, not the number of objects."], "extent": [55614, 55758]}], "container": true}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["Remember that the first time a light source is refracted through a surface, it is considered a direct refraction. Therefore, even with ", {"type": "ui", "text": ["Refract Limit"]}, " set to ", {"type": "code", "text": ["0"]}, ", you will see refraction of light sources. However, since most objects in your scene will have at least two surfaces between it and the light source, direct refraction is often not evident in your final render."], "extent": [55758, 56138]}, {"type": "box_group", "body": [{"ext": null, "type": "box", "indent": 4, "role": "item", "extent": [53083, 53093], "body": [{"type": "para", "indent": 8, "text": ["This is a float because all limits are stochastically picked per-sample, so for example you can set the diffuse limit to ", {"type": "code", "text": ["3.25"]}, " and have 25% of the rays with a diffuse limit of ", {"type": "code", "text": ["4"]}, " and 75% of rays with a diffuse limit of ", {"type": "code", "text": ["3"]}, "."], "extent": [53125, 53360]}], "container": true, "attrs": {"id": "stochastic_limits"}}], "container": true, "role": "item_group"}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Volume Limit"], "extent": [3157, 3175], "body": [{"type": "para", "indent": 4, "text": ["The number of times a volumetric ray can propagate through a scene. It functions in a similar fashion to the ", {"type": "ui", "text": ["Diffuse Limit"]}, " parameter."], "extent": [56247, 56390]}, {"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/limits_tab/VolumeLimit.jpg", "type": "img", "text": ""}], "role": "item", "extent": [56390, 56454]}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["Increasing the ", {"type": "ui", "text": ["Volume Limit"]}, " parameter will result in much more realistic volumetric effects. This is especially noticeable in situations where only part of a volume is receiving direct lighting. Also, in order for a volumetric object to receive indirect light from other objects, the ", {"type": "ui", "text": ["Volume Limit"]}, " parameter must be set above ", {"type": "code", "text": ["0"]}, "."], "extent": [56454, 56797]}, {"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/limits_tab/VolumeLimitCompare.jpg", "type": "img", "text": ""}], "role": "item", "extent": [56797, 56868]}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["With the ", {"type": "ui", "text": ["Volume Limit"]}, " set to values greater than ", {"type": "code", "text": ["0"]}, ", the fog volume takes on the characteristic light scattering you would expect from light traveling through a volume. However, as with the ", {"type": "ui", "text": ["Diffuse Limit"]}, ", the light contribution generally decreases with each bounced ray and therefore using values above ", {"type": "code", "text": ["4"]}, " does not necessarily result in a noticeably more realistic image."], "extent": [56868, 57255]}, {"type": "para", "indent": 4, "text": ["Also, increasing the value of this parameter can dramatically increase the amount of time spent rendering volumetric images."], "extent": [57255, 57385]}, {"type": "box_group", "body": [{"ext": null, "type": "box", "indent": 4, "role": "item", "extent": [53083, 53093], "body": [{"type": "para", "indent": 8, "text": ["This is a float because all limits are stochastically picked per-sample, so for example you can set the diffuse limit to ", {"type": "code", "text": ["3.25"]}, " and have 25% of the rays with a diffuse limit of ", {"type": "code", "text": ["4"]}, " and 75% of rays with a diffuse limit of ", {"type": "code", "text": ["3"]}, "."], "extent": [53125, 53360]}], "container": true, "attrs": {"id": "stochastic_limits"}}], "container": true, "role": "item_group"}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["SSS Limit"], "extent": [3242, 3257], "body": [{"type": "para", "indent": 4, "text": ["The number of times a SSS ray can propagate through a scene. It functions\n    in a similar fashion to the ", {"type": "ui", "text": ["Diffuse Limit"]}, " parameter."], "extent": [57488, 57628]}, {"type": "box_group", "body": [{"ext": null, "type": "box", "indent": 4, "role": "item", "extent": [53083, 53093], "body": [{"type": "para", "indent": 8, "text": ["This is a float because all limits are stochastically picked per-sample, so for example you can set the diffuse limit to ", {"type": "code", "text": ["3.25"]}, " and have 25% of the rays with a diffuse limit of ", {"type": "code", "text": ["4"]}, " and 75% of rays with a diffuse limit of ", {"type": "code", "text": ["3"]}, "."], "extent": [53125, 53360]}], "container": true, "attrs": {"id": "stochastic_limits"}}], "container": true, "role": "item_group"}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Color Limit"], "extent": [3321, 3338], "body": [{"type": "para", "indent": 4, "text": ["The maximum value a shading sample is allowed to contribute to an LPE image\n    plane to reduce appearance of ", {"type": "q", "text": ["fireflies"]}, " caused by undersampling of \n    extremely bright light sources. Note that reducing this value can result in\n    an overall reduction in the amount of light in your scene."], "extent": [20959, 21257]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Shared Color Limit"], "extent": [3404, 3428], "body": [{"type": "para", "indent": 4, "text": ["When turned on, indirect bounces use ", {"type": "ui", "text": ["Color Limit"]}, " value and ", {"type": "ui", "text": ["Indirect Color\n    Limit"]}, " parameter is ignored."], "extent": [21573, 21692]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Indirect Color Limit"], "extent": [3503, 3529], "body": [{"type": "para", "indent": 4, "text": ["Color limit applied to indirect bounce only. Note that this parameter is\n    ignored unless ", {"type": "ui", "text": ["Shared Color Limit"]}, " is turned off."], "extent": [21348, 21483]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Russian Roulette Cutoff Depth"], "extent": [3603, 3638], "body": [{"type": "para", "indent": 4, "text": ["Depth at which indirect rays start to get stochastically pruned based on\n    ray throughput."], "extent": [7778, 7876]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 3, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Camera Effects"], "extent": [3716, 3743], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Enable Depth of Field"], "extent": [3743, 3771], "body": [{"type": "para", "indent": 4, "text": ["Turn on the depth of field rendering."], "extent": [2752, 2795]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Motion Blur"], "extent": [3837, 3854], "body": [{"type": "para", "indent": 4, "text": ["Whether to turn on motion blur. Changing this in the display options will\n    require a restart of the render."], "extent": [39871, 39987]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Per-object Motion Blur"], "extent": [3915, 3943], "body": [{"type": "para", "indent": 8, "text": ["Whether motion blur should be on or off for objects that don\u2019t explicitly have an opinion. If this is ", {"type": "ui", "text": ["On by default"]}, ", the parameters below let you set the defaults."], "extent": [3963, 4140]}], "container": true, "attrs": {"id": "mblur"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Transform Time Samples"], "extent": [4140, 4168], "body": [{"type": "para", "indent": 4, "text": ["The number of samples to compute when rendering ", {"type": "em", "text": ["transformation"]}, " motion blur over the shutter open time.  The default is 2 samples (at the start and end of the shutter time), giving one blurred segment."], "extent": [45796, 46004]}, {"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/blur/XFormSampleSimple.jpg", "type": "img", "text": ""}], "role": "item", "extent": [46004, 46068]}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["If you have object moving and changing direction extremely quickly, you might want to increase the number of samples to capture the sub-frame direction changes."], "extent": [46068, 46234]}, {"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/blur/XFormSampleComplex.jpg", "type": "img", "text": ""}], "role": "item", "extent": [46234, 46299]}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["In the above example, it requires 40 transformation samples to correctly render the complex motion that occurs within one frame. (This amount of change within a single frame is very unusual and only used as a demonstration.)"], "extent": [46299, 46529]}, {"type": "para", "indent": 4, "text": ["Transformation blur simulates blur by interpolating each object\u2019s transformation between frames, so it\u2019s cheap to compute but does not capture surface deformation. To enable blurring deforming geometry, increase ", {"scheme": "Karma", "value": "karma:object:geosamples", "type": "link", "text": "", "exists": true}, "."], "extent": [46529, 46779]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Geometry Time Samples"], "extent": [4236, 4263], "body": [{"type": "para", "indent": 4, "text": ["The number of sub-frame samples to compute when rendering ", {"type": "em", "text": ["deformation"]}, " motion blur over the shutter open time. The default is 1 (sample only at the start of the shutter time), giving ", {"type": "strong", "text": ["no"]}, " deformation blur by default. If you want rapidly deforming geometry to blur properly, you must increase this value to 2 or more. Note that this value is limited by the number of sub-samples available in the USD file being rendered.  An exception to this is the USD Skel deformer which allows."], "extent": [44105, 44592]}, {"type": "para", "indent": 4, "text": [{"type": "q", "text": ["Deformation"]}, " may refer to simple transformations at the Geometry (SOP) level, or actual surface deformation, such as a character or object which changes shape rapidly over the course of a frame."], "extent": [44592, 44793]}, {"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/blur/GeoTimeSamplesSimple.jpg", "type": "img", "text": ""}], "role": "item", "extent": [44793, 44860]}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["Objects whose deformations are quite complex within a single frame will require a higher number of Geo Time Samples."], "extent": [44860, 44982]}, {"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 4, "text": [{"scheme": "Image", "value": "/images/render/mug/blur/GeoTimeSamples.jpg", "type": "img", "text": ""}], "role": "item", "extent": [44982, 45043]}], "container": true, "role": "item_group"}, {"type": "para", "indent": 4, "text": ["Deformation blur also lets you blur ", {"type": "em", "text": ["attribute change"]}, " over the shutter time. For example, if point colors are changing rapidly as the object moves, you can blur the ", {"type": "code", "text": ["Cd"]}, " attribute."], "extent": [45043, 45230]}, {"type": "para", "indent": 4, "text": ["Increasing the number of Geo Time Samples ", {"type": "strong", "text": ["can have an impact"]}, " on the amount of memory Karma uses.  For each additional Sample, Karma must retain a copy of the geometry in memory while it samples across the shutter time. When optimizing your renders, it is a good idea to find the minimum number of Geo Time Samples necessary to create a smooth motion trail."], "extent": [45230, 45594]}, {"type": "para", "indent": 4, "text": ["Deformation blur is ignored for objects that have ", {"scheme": null, "value": "/render/blur#velocity", "type": "link", "text": ["Velocity motion blur"], "fullpath": "/render/blur.html#velocity", "fragment": "#velocity"}, " turned on."], "extent": [45594, 45705]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Velocity Blur"], "extent": [4329, 4348], "body": [{"type": "para", "indent": 4, "text": ["This parameter lets you choose what type of ", {"type": "em", "text": ["geometry velocity blur"]}, " to do on an object, if any. Separate from ", {"type": "em", "text": ["transform blur"]}, " and ", {"type": "em", "text": ["deformation blur"]}, ", you can render motion blur based on point movement, using attributes stored on the points that record change over time. You should use this type of blur if the number points in the geometry changes over time (for example, a particle simulation where points are born and die)."], "extent": [40787, 41220]}, {"type": "para", "indent": 4, "text": ["If your geometry changes topology frame-to-frame, Karma will not be able to interpolate the geometry to correctly calculate Motion Blur. In these cases, motion blur can use a ", {"type": "code", "text": ["velocities"]}, " and/or ", {"type": "code", "text": ["accelerations"]}, " attribute which is consistent even while the underlying geometry is changing. The surface of a fluid simulation is a good example of this. In this case, and other types of simulation data, the solvers will automatically create the velocity attribute."], "extent": [41220, 41687]}, {"type": "note_group", "body": [{"type": "note", "indent": 4, "text": [" "], "role": "item", "extent": [41687, 41698], "body": [{"type": "para", "indent": 8, "text": ["In Solaris, ", {"type": "code", "text": ["velocities"]}, ", ", {"type": "code", "text": ["accelerations"]}, ", and ", {"type": "code", "text": ["angularVelocities"]}, " attributes are equivalent to ", {"type": "code", "text": ["v"]}, ", ", {"type": "code", "text": ["accel"]}, ", and ", {"type": "code", "text": ["w"]}, " in SOPs, respectively."], "extent": [41698, 41848]}], "container": true}], "container": true, "role": "item_group"}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": ["No Velocity Blur"], "extent": [41848, 41870], "body": [{"type": "para", "indent": 8, "text": ["Do not render motion blur on this object, even if the renderer is set to allow motion blur."], "extent": [41870, 41971]}], "container": true}, {"type": "dt", "indent": 4, "text": ["Velocity Blur"], "extent": [41971, 41990], "body": [{"type": "para", "indent": 8, "text": ["To use velocity blur, you must compute and store point velocities in a point attribute ", {"type": "code", "text": ["velocities"]}, ". The renderer uses this attribute, if it exists, to render velocity motion blur (assuming the renderer is set to allow motion blur). The ", {"type": "code", "text": ["velocities"]}, " attribute may be created automatically by simulation nodes (such as particle DOPs), or you can compute and add it using the ", {"scheme": "Node", "value": "/nodes/sop/pointvelocity", "type": "link", "text": ["Point velocity SOP"], "fullpath": "/nodes/sop/pointvelocity.html"}, "."], "extent": [41990, 42418]}, {"type": "para", "indent": 8, "text": ["The ", {"type": "code", "text": ["velocities"]}, " attribute value is measured in Houdini units per second."], "extent": [42418, 42501]}], "container": true}, {"type": "dt", "indent": 4, "text": ["Acceleration Blur"], "extent": [42501, 42524], "body": [{"type": "para", "indent": 8, "text": ["To use acceleration blur, you must compute and store point acceleration in a point attribute ", {"type": "code", "text": ["accelerations"]}, ". The renderer uses this attribute, if it exists, to render multi-segment acceleration motion blur (assuming the renderer is set to allow motion blur). The ", {"type": "code", "text": ["accel"]}, " attribute may be created automatically by simulation nodes, or you can compute and add it using the ", {"scheme": "Node", "value": "/nodes/sop/pointvelocity", "type": "link", "text": ["Point velocity SOP"], "fullpath": "/nodes/sop/pointvelocity.html"}, "."], "extent": [42524, 42950]}, {"type": "para", "indent": 8, "text": ["When Acceleration Blur is on, if the geometry has a ", {"type": "em", "text": ["angular velocity"]}, " attribute (", {"type": "code", "text": ["w"]}, "), rapid rotation will also be blurred. This should be a vector attribute, where the components represent rotation speeds in radians per second around X, Y, and Z."], "extent": [42950, 43208]}], "container": true}], "container": true}, {"type": "para", "indent": 4, "text": ["When this is set to ", {"type": "q", "text": ["Velocity Blur"]}, " or ", {"type": "q", "text": ["Acceleration Blur"]}, ", deformation blur is not applied to the object. When this is set to ", {"type": "q", "text": ["Acceleration Blur"]}, ", use the ", {"scheme": "Karma", "value": "karma:object:geosamples", "type": "link", "text": "", "exists": true}, " property to set the number of acceleration samples."], "extent": [43208, 43453]}, {"type": "col_group", "body": [{"ext": null, "type": "col", "indent": 4, "role": "item", "extent": [43453, 43463], "body": [{"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 8, "text": [{"scheme": "Image", "value": "/images/render/motionblur_velocity.jpg", "type": "img", "text": ""}], "role": "item", "extent": [43463, 43523], "body": [{"type": "summary", "indent": 12, "text": ["Velocity motion blur used the velocity attribute (", {"type": "code", "text": ["velocities"]}, ") to do linear motion blur."], "extent": [43523, 43631]}], "container": true}], "container": true, "role": "item_group"}], "container": true}, {"ext": null, "type": "col", "indent": 4, "role": "item", "extent": [43631, 43641], "body": [{"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 8, "text": [{"scheme": "Image", "value": "/images/render/motionblur_acceleration.jpg", "type": "img", "text": ""}], "role": "item", "extent": [43641, 43705], "body": [{"type": "summary", "indent": 12, "text": ["Acceleration motion blur uses the change in velocity to more accurately blur objects turning at high speed."], "extent": [43705, 43831]}], "container": true}], "container": true, "role": "item_group"}], "container": true}, {"ext": null, "type": "col", "indent": 4, "role": "item", "extent": [43831, 43841], "body": [{"type": "fig_group", "body": [{"ext": null, "type": "fig", "indent": 8, "text": [{"scheme": "Image", "value": "/images/render/motionblur_angular_acceleration.jpg", "type": "img", "text": ""}], "role": "item", "extent": [43841, 43913], "body": [{"type": "summary", "indent": 12, "text": ["Angular acceleration blur works with object spin, such as these fast-spinning cubes."], "extent": [43913, 44017]}], "container": true}], "container": true, "role": "item_group"}], "container": true}], "container": true, "role": "item_group"}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Instance Velocity Blur"], "extent": [4409, 4437], "body": [{"type": "para", "indent": 4, "text": ["When defining motion blur on instances, the transform of each instance can be blurred in addition to any motion blur occurring on the prototype.  This option controls how the instance will compute the motion blur of the transform on each instance.  For example, when instancing prototypes to a particle system, you'd likely want to use velocity blur to compute motion blur (the transform on the prototype would be blurred by the velocity on the particles)."], "extent": [46872, 47334]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": ["No Velocity Blur"], "extent": [47334, 47356], "body": [{"type": "para", "indent": 8, "text": ["Use deformation blur of the instance to compute the blur on the transform."], "extent": [47356, 47440]}], "container": true}, {"type": "dt", "indent": 4, "text": ["Velocity Blur"], "extent": [47440, 47459], "body": [{"type": "para", "indent": 8, "text": ["To use velocity blur, the instance must be a point instancer with velocity attributes on the points."], "extent": [47459, 47569]}, {"type": "para", "indent": 8, "text": ["The ", {"type": "code", "text": ["velocities"]}, " attribute value is measured in Houdini units per second."], "extent": [47569, 47652]}], "container": true}, {"type": "dt", "indent": 4, "text": ["Acceleration Blur"], "extent": [47652, 47675], "body": [{"type": "para", "indent": 8, "text": ["To use acceleration blur, the instance must be a point instancer with point velocities and acceleration values.  The renderer uses this attribute, if it exists, to render multi-segment acceleration motion blur (assuming the renderer is set to allow motion blur). The ", {"type": "code", "text": ["accel"]}, " attribute may be created automatically by simulation nodes, or you can compute and add it using the ", {"scheme": "Node", "value": "/nodes/sop/pointvelocity", "type": "link", "text": ["Point velocity SOP"], "fullpath": "/nodes/sop/pointvelocity.html"}, "; this will be converted to ", {"type": "code", "text": ["accelerations"]}, " when the SOP geometry is converted to USD."], "extent": [47675, 48189]}], "container": true}], "container": true}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Instance Motion Samples"], "extent": [4507, 4536], "body": [{"type": "para", "indent": 4, "text": ["When motion blur on instances is computed using ", {"type": "ui", "text": ["Acceleration Blur"]}, " or ", {"type": "ui", "text": ["Deformation Blur"]}, ", this parameter specifies the number of motion segments used for motion blur."], "extent": [48285, 48462]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Motion Blur Style"], "extent": [4608, 4631], "body": [], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Instance Velocity Blur Scale"], "extent": [4696, 4730], "body": [{"type": "para", "indent": 4, "text": ["Velocity multiplier used to reduce or exaggerate amount of motion blur on\n    volumes."], "extent": [61460, 61552]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Disable Image Blur"], "extent": [4802, 4826], "body": [{"type": "para", "indent": 4, "text": ["If you turn this off, Karma still calculates velocities, but sends all camera rays at shutter open, so the image will not have any apparent motion blur. This may be useful if you simply don\u2019t want any motion blur. For example, if you want to add motion blur in post/compositing, but you still need the renderer to be aware of motion blur so that it saves out the proper motion vectors to an AOV."], "extent": [8626, 9027]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 3, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Geometry and Shading"], "extent": [4903, 4936], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Render Points as"], "extent": [4936, 4959], "body": [{"type": "para", "indent": 4, "text": ["When rendering point clouds, they can be rendered as camera oriented\n    discs, spheres or discs oriented to the normal attribute."], "extent": [63723, 63859]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Render Curves as"], "extent": [5026, 5048], "body": [{"type": "para", "indent": 4, "text": ["When rendering curves, they can be rendered as ribbons oriented to face\n    the camera, rounded tubes or ribbons oriented to the normal attribute\n    attached to the points."], "extent": [63940, 64119]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Override Curve Basis"], "extent": [5115, 5141], "body": [{"type": "para", "indent": 4, "text": ["USD supports ", {"type": "ui", "text": ["Curve Basis"]}, " types that may not be supported directly in\n    Houdini.  In some cases, you may want to override the Houdini curve basis.\n    For example, if you have linear curves in Houdini, you may want to render\n    them with a Bezier, B-Spline or Catmull-Rom basis.  This menu will force\n    Karma to override the basis that\u2019s tied to the USD primitives."], "extent": [64205, 64584]}, {"type": "para", "indent": 4, "text": ["Note that the topology of the curves must match the target basis.  For\n    example, when selecting any cubic curve basis, every curves must have at\n    least 4 vertices.  For the Bezier basis, curves must have ", {"type": "code", "text": ["4+3*N"]}, " vertices."], "extent": [64584, 64817]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Cull Backfaces"], "extent": [5208, 5228], "body": [{"type": "para", "indent": 4, "text": ["If enabled, geometry that are facing away from the camera are not\n    rendered."], "extent": [64897, 64982]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Enable Caustics"], "extent": [5297, 5318], "body": [{"type": "para", "indent": 4, "text": ["Allows evaluation of glossy BSDF that\u2019s seen by indirect diffuse bounce.\n    This is a brute-force solution which may require significant number of\n    diffuse rays to resolve, especially if Caustics Roughness Clamp parameter\n    is set to very small value or Indirect Guiding feature is disabled."], "extent": [66325, 66628]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Caustics Roughness Clamp"], "extent": [5388, 5418], "body": [{"type": "para", "indent": 4, "text": ["Increasing this value can make caustics less noisy at the cost of accuracy."], "extent": [66728, 66809]}, {"type": "note_group", "body": [{"type": "note", "indent": 4, "role": "item", "extent": [66809, 66819], "body": [{"type": "para", "indent": 8, "text": ["Roughness clamp only works with GGX BSDF and may not have any effect\n        with Phong, cone, or specular BSDFs."], "extent": [66819, 66942]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "role": "item"}], "container": true, "role": "item_group"}, {"level": 3, "type": "sep", "indent": 4, "text": [" Shading "], "extent": [5496, 5516]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Ray Bias"], "extent": [5516, 5531], "body": [{"type": "para", "indent": 4, "text": ["The minimum distance used when testing if ", {"type": "em", "text": ["secondary rays"]}, " from a surface intersect with other objects in the scene. The distance is measure from surface along the direction of the ray. Objects within the ray bias distance are ignored."], "extent": [13175, 13416]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Automatic Ray Bias"], "extent": [5594, 5618], "body": [{"type": "para", "indent": 4, "text": ["Automatically compute ideal ray bias. Under Karma CPU, automatic bias\n    applies to everything except procedural mesh and continued rays for\n    partially opaque surfaces and nested dielectrics (the ", {"type": "q", "text": ["Ray Bias"]}, " property\n    is still used for those cases). Under Karma XPU, automatic bias applies to\n    polymesh path bounce and polymesh shadow rays only.  For everything else\n    (eg SSS, rounded-edge, nested dielectrics, points, curves etc\u2026) the \n    ", {"type": "q", "text": ["Ray Bias"]}, " property is still used."], "extent": [14487, 14982]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Constrain by Maximum Roughness"], "extent": [5695, 5731], "body": [{"type": "para", "indent": 4, "text": ["Roughness parameter in GGX BSDFs are clamped by the maximum roughness value\n    propagated down the ray chain in pathtracing. Enabling this option can cut\n    out a lot of noise in indirect specular (in particular, cases where glossy\n    surface is reflected by a rough specular surface) at the cost of a bit of\n    accuracy."], "extent": [7976, 8307]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Shading Quality Multiplier"], "extent": [5804, 5836], "body": [{"type": "para", "indent": 4, "text": ["A multiplier on the shading quality.  This is used for texture and area\n    evaluations in shading."], "extent": [8404, 8509]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Automatic Headlight Creation"], "extent": [5910, 5944], "body": [{"type": "para", "indent": 4, "text": ["If there are no lights in the scene, a headlight is created by default. To disable, turn off this checkbox."], "extent": [2321, 2434]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}, {"level": 3, "type": "sep", "indent": 4, "text": [" Dicing "], "extent": [6013, 6032]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Dicing Camera"], "extent": [6032, 6052], "body": [{"type": "para", "indent": 4, "text": ["Specifies a camera that is used for dicing complicated surfaces.  This can\n    provide consistent dicing of surfaces when the viewing camera is moving."], "extent": [2511, 2668]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Offscreen Quality"], "extent": [6120, 6143], "body": [{"type": "para", "indent": 4, "text": ["This parameter controls the shading quality scale factor for geometry that\n    is not directly visible to the camera. For geometry that is outside the\n    field of view (i.e. visible only to secondary rays), karma will smoothly\n    reduce the shading quality based on the angle between the geometry and the\n    edge of the viewing frustum.  Smaller values can increase performance\n    particularly in scenes where the camera is within the displacement bound of\n    nearby geometry, where it permits the hidden primitives to be diced more\n    coarsely than those that are directly visible."], "extent": [20291, 20885]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Dicing Quality Scale"], "extent": [6215, 6241], "body": [{"type": "para", "indent": 4, "text": ["This parameter is a global multiplier for dicing quality of all objects."], "extent": [19736, 19814]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}]}, {"level": 2, "id": "image_output_tab", "container": true, "type": "h", "indent": 0, "text": ["Image Output"], "extent": [6316, 6354], "body": [{"level": 3, "id": null, "container": true, "type": "h", "indent": 4, "text": ["AOVs (Render Vars)"], "extent": [6354, 6386], "body": [{"type": "para", "indent": 8, "text": ["In USD, a ", {"type": "code", "text": ["RenderVar"]}, " prim (for example, ", {"type": "code", "text": ["/Render/Products/Vars/diffuse"]}, ") configures an AOV (arbitrary output variable) to generate during rendering. AOVs are extra ", {"type": "q", "text": ["channels"]}, " of per-pixel data you can add to the image output (for image formats that support multiple channels per pixel, such as ", {"type": "code", "text": [".exr"]}, ")."], "extent": [6386, 6700]}, {"type": "para", "indent": 8, "text": ["By default, this node generates ", {"type": "code", "text": ["beauty"]}, ", ", {"type": "code", "text": ["diffuse"]}, ", ", {"type": "code", "text": ["glossy reflection"]}, ", ", {"type": "code", "text": ["volume"]}, ", ", {"type": "code", "text": ["depth"]}, ", ", {"type": "code", "text": ["UV"]}, " and ", {"type": "code", "text": ["normal"]}, " AOVs."], "extent": [6700, 6826]}, {"type": "para", "indent": 8, "text": ["The checkboxes in this section represent commonly used AOVs. You can also create custom AOVs (in the ", {"type": "ui", "text": ["Extra Render Vars"]}, " section) from ", {"scheme": null, "value": "/render/lpe", "type": "link", "text": ["light path expressions"], "fullpath": "/render/lpe.html"}, ", material outputs, geometry primvars, and other sources."], "extent": [6826, 7066]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 8, "text": ["Import Render Vars from Second Input"], "extent": [7066, 7112], "body": [{"type": "para", "indent": 12, "text": ["Finds ", {"type": "code", "text": ["RenderVar"]}, " prims in this node\u2019s second input and adds them to this stage, so they add to the list of render vars to generate. This allows other LOP nodes (such as ", {"scheme": "Node", "value": "/nodes/lop/backgroundplate", "type": "link", "text": ["Background Plate"], "fullpath": "/nodes/lop/backgroundplate.html"}, ") to ", {"type": "q", "text": ["offer"]}, " render vars related to that node to be generated."], "extent": [7155, 7444]}], "container": true, "attrs": {"id": "importsecondaryinputvars"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Import Render Products from Second Input"], "extent": [7444, 7494], "body": [{"type": "para", "indent": 12, "text": ["Finds RenderProduct prims in this node\u2019s second input and adds them to this stage, so they add to the list of products to generate. This allows other LOP nodes to ", {"type": "q", "text": ["offer"]}, " products related to that node to be generated."], "extent": [7536, 7767]}], "container": true, "attrs": {"id": "importsecondaryproducts"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Pixel Filter"], "extent": [7767, 7789], "body": [{"type": "para", "indent": 4, "text": ["Specifies the distribution of samples over pixels.  A box filter will\n    distribute samples randomly over the interior of each individual pixel.  A\n    Gaussian filter will distribute samples in a disk around the pixel center,\n    but with a Gaussian distribution (instead of a uniform distribution)."], "extent": [9833, 10140]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Pixel Filter Size"], "extent": [7860, 7887], "body": [{"type": "para", "indent": 4, "text": ["This is the size of the Pixel Filter.  A Gaussian filter with a filter size\n    of 1.8 will be slightly less blurry than a Gaussian filter with a filter\n    size of 2.0."], "extent": [10223, 10398]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}, {"type": "para", "indent": 8, "text": ["The following checkbox is available next to each common render var:"], "extent": [7962, 8039]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 8, "text": ["Split Per LPE Tag"], "extent": [8202, 8229], "body": [{"type": "para", "indent": 12, "text": ["When this is on, the renderer creates additional AOVs specific to each tagged light. To manage LPE Tags for lights, use the ", {"scheme": "Node", "value": "/nodes/lop/lpetag", "type": "link", "text": ["LPE Tag LOP"], "fullpath": "/nodes/lop/lpetag.html"}, "."], "extent": [8229, 8397]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}, {"level": 4, "id": null, "container": true, "type": "h", "indent": 8, "text": ["Component Level Output"], "extent": [8397, 8438], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["LPE Tag AOV Limit"], "extent": [558, 578], "body": [{"type": "para", "indent": 4, "text": ["When splitting AOVs per lights' LPE Tag, specify the maximum number of LPE Tag AOVs beyond which the node will emit a warning."], "extent": [600, 732]}], "container": true, "attrs": {"id": "lpeaovlimit"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Omit LPE Tags"], "extent": [732, 747], "body": [{"type": "para", "indent": 4, "text": ["When splitting AOVs per lights' LPE Tag, specify a space separated list of lights' LPE Tags which will not create new AOVs."], "extent": [766, 895]}], "container": true, "attrs": {"id": "omitlpes"}, "role": "item"}, {"type": "parameters_item", "indent": 12, "text": ["Output Colorspace"], "extent": [8554, 8585], "body": [{"type": "para", "indent": 16, "text": ["Specify the ", {"scheme": null, "value": "/io/ocio", "type": "link", "text": ["OCIO"], "fullpath": "/io/ocio.html"}, " color output space for the component."], "extent": [8616, 8699]}], "container": true, "attrs": {"id": "outputcs"}, "role": "item"}], "container": true, "role": "item_group"}, {"level": 3, "type": "sep", "indent": 12, "text": [" Beauty "], "extent": [8699, 8726], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Beauty"], "extent": [1509, 1518], "body": [{"type": "para", "indent": 4, "text": ["Add the beauty output as a ", {"type": "code", "text": ["color4f"]}, " render var named ", {"type": "code", "text": ["C"]}, "."], "extent": [1535, 1599]}], "container": true, "attrs": {"id": "beauty"}, "role": "item"}, {"type": "parameters_item", "indent": 16, "text": ["Pixel Filter"], "extent": [8785, 8815], "body": [{"type": "para", "indent": 20, "text": ["You can use ", {"scheme": null, "value": "/solaris/filters", "type": "link", "text": ["Solaris filter syntax"], "fullpath": "/solaris/filters.html"}, " in this parameter to filter the sample values. The default ", {"type": "code", "text": ["[\"ubox\", {}]"]}, " simply averages all the sample values within each pixel."], "extent": [8854, 9059]}], "container": true, "attrs": {"id": "beautyfilter"}, "role": "item"}, {"type": "parameters_item", "indent": 12, "text": ["Output Colorspace"], "extent": [8554, 8585], "body": [{"type": "para", "indent": 16, "text": ["Specify the ", {"scheme": null, "value": "/io/ocio", "type": "link", "text": ["OCIO"], "fullpath": "/io/ocio.html"}, " color output space for the component."], "extent": [8616, 8699]}], "container": true, "attrs": {"id": "outputcs"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Beauty Unshadowed"], "extent": [1599, 1618], "body": [{"type": "para", "indent": 4, "text": ["Add the unoccluded (unshadowed) beauty output as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["beautyunshadowed"]}, ", using the LPE ", {"type": "code", "text": ["unoccluded;C.*[LO][LO]"]}, "."], "extent": [1645, 1788]}], "container": true, "attrs": {"id": "beautyunshadowed"}, "role": "item"}], "container": true, "role": "item_group"}], "container": true}, {"level": 3, "type": "sep", "indent": 12, "text": [" Diffuse "], "extent": [9185, 9213], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Combined Diffuse"], "extent": [1788, 1806], "body": [{"type": "para", "indent": 4, "text": ["Add the combined (any number of bounces) diffuse surface reflection component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["combineddiffuse"]}, ", using the LPE ", {"type": "code", "text": ["C<RD>.*L"]}, "."], "extent": [1832, 1992]}], "container": true, "attrs": {"id": "combineddiffuse"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Direct Diffuse"], "extent": [1992, 2008], "body": [{"type": "para", "indent": 4, "text": ["Add the direct (no bounces) diffuse surface reflection component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["directdiffuse"]}, ", using the LPE ", {"type": "code", "text": ["C<RD>L"]}, "."], "extent": [2032, 2175]}], "container": true, "attrs": {"id": "directdiffuse"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Indirect Diffuse"], "extent": [2175, 2193], "body": [{"type": "para", "indent": 4, "text": ["Add the indirect (one or more bounces) diffuse surface reflection component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["indirectdiffuse"]}, ", using the LPE ", {"type": "code", "text": ["C<RD>.+L"]}, "."], "extent": [2219, 2377]}], "container": true, "attrs": {"id": "indirectdiffuse"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Combined Diffuse Unshadowed"], "extent": [2377, 2406], "body": [{"type": "para", "indent": 4, "text": ["Add the combined (any number of bounces) unoccluded diffuse surface reflection component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["combineddiffuseunshadowed"]}, ", using the LPE ", {"type": "code", "text": ["unoccluded;C<RD>.*[LO]"]}, "."], "extent": [2442, 2637]}], "container": true, "attrs": {"id": "combineddiffuseunshadowed"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Direct Diffuse Unshadowed"], "extent": [2637, 2664], "body": [{"type": "para", "indent": 4, "text": ["Add the direct (no bounces) unoccluded diffuse surface reflection component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["directdiffuseunshadowed"]}, ", using the LPE ", {"type": "code", "text": ["unoccluded;C<RD>L"]}, "."], "extent": [2698, 2873]}], "container": true, "attrs": {"id": "directdiffuseunshadowed"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Indirect Diffuse Unshadowed"], "extent": [2873, 2902], "body": [{"type": "para", "indent": 4, "text": ["Add the indirect (one or more bounces) unoccluded diffuse surface reflection component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["indirectdiffuseunshadowed"]}, ", using the LPE ", {"type": "code", "text": ["unoccluded;C<RD>.+L"]}, "."], "extent": [2938, 3128]}], "container": true, "attrs": {"id": "indirectdiffuseunshadowed"}, "role": "item"}], "container": true, "role": "item_group"}], "container": true}, {"level": 3, "type": "sep", "indent": 12, "text": [" Reflections and Refractions "], "extent": [9642, 9690], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Combined Glossy Reflection"], "extent": [3128, 3156], "body": [{"type": "para", "indent": 4, "text": ["Add the combined (any number of bounces) glossy surface reflection component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["combinedglossyreflection"]}, ", using the LPE ", {"type": "code", "text": ["C<RG>.*[LO]"]}, "."], "extent": [3195, 3366]}], "container": true, "attrs": {"id": "combinedglossyreflection"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Direct Glossy Reflection"], "extent": [3366, 3392], "body": [{"type": "para", "indent": 4, "text": ["Add the direct (no bounces) glossy surface reflection component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["directglossyreflection"]}, ", using the LPE ", {"type": "code", "text": ["C<RG>L"]}, "."], "extent": [3425, 3576]}], "container": true, "attrs": {"id": "directglossyreflection"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Indirect Glossy Reflection"], "extent": [3576, 3604], "body": [{"type": "para", "indent": 4, "text": ["Add the indirect (one or more bounces) glossy reflection component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["indirectglossyreflection"]}, ", using the LPE ", {"type": "code", "text": ["C<RG>.+L"]}, "."], "extent": [3639, 3797]}], "container": true, "attrs": {"id": "indirectglossyreflection"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Glossy Transmission"], "extent": [3797, 3818], "body": [{"type": "para", "indent": 4, "text": ["Add the glossy transmission component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["glossytransmission"]}, ", using the LPE ", {"type": "code", "text": ["C<TG>.*[LO]"]}, "."], "extent": [3847, 3973]}], "container": true, "attrs": {"id": "glossytransmission"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["BSDF Labelled ", {"type": "code", "text": ["coat"]}], "extent": [5163, 5185], "body": [{"type": "para", "indent": 4, "text": ["Add the coat component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["coat"]}, ", using the LPE ", {"type": "code", "text": ["C<...'coat'>.*[LO]"]}, "."], "extent": [5200, 5304]}], "container": true, "attrs": {"id": "coat"}, "role": "item"}], "container": true, "role": "item_group"}], "container": true}, {"level": 3, "type": "sep", "indent": 12, "text": [" Lights and Emission "], "extent": [10043, 10083], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Combined Emission"], "extent": [4120, 4139], "body": [{"type": "para", "indent": 4, "text": ["Add the combined (any number of bounces) emission component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["combinedemission"]}, ", using the LPE ", {"type": "code", "text": ["C.*O"]}, "."], "extent": [4166, 4305]}], "container": true, "attrs": {"id": "combinedemission"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Direct Emission"], "extent": [4305, 4322], "body": [{"type": "para", "indent": 4, "text": ["Add the direct (no bounces) emission component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["directemission"]}, ", using the LPE ", {"type": "code", "text": ["CO"]}, "."], "extent": [4347, 4469]}], "container": true, "attrs": {"id": "directemission"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Indirect Emission"], "extent": [4469, 4488], "body": [{"type": "para", "indent": 4, "text": ["Add the indirect (one or more bounces) emission component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["indirectemission"]}, ", using the LPE ", {"type": "code", "text": ["C.+O"]}, "."], "extent": [4515, 4652]}], "container": true, "attrs": {"id": "indirectemission"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Visible Lights"], "extent": [3973, 3989], "body": [{"type": "para", "indent": 4, "text": ["Add the visible lights component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["visiblelights"]}, ", using the LPE ", {"type": "code", "text": ["CL"]}, "."], "extent": [4013, 4120]}], "container": true, "attrs": {"id": "visiblelights"}, "role": "item"}], "container": true, "role": "item_group"}], "container": true}, {"level": 3, "type": "sep", "indent": 12, "text": [" Volume "], "extent": [10351, 10378], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Combined Volume"], "extent": [4652, 4669], "body": [{"type": "para", "indent": 4, "text": ["Add the combined (any number of bounces) volume component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["combinedvolume"]}, ", using the LPE ", {"type": "code", "text": ["CV.*L"]}, "."], "extent": [4694, 4830]}], "container": true, "attrs": {"id": "combinedvolume"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Direct Volume"], "extent": [4830, 4845], "body": [{"type": "para", "indent": 4, "text": ["Add the direct (no bounces) volume component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["directvolume"]}, ", using the LPE ", {"type": "code", "text": ["CVL"]}, "."], "extent": [4868, 4987]}], "container": true, "attrs": {"id": "directvolume"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Indirect Volume"], "extent": [4987, 5004], "body": [{"type": "para", "indent": 4, "text": ["Add the indirect (one or more bounces) volume component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["indirectvolume"]}, ", using the LPE ", {"type": "code", "text": ["CV.+L"]}, "."], "extent": [5029, 5163]}], "container": true, "attrs": {"id": "indirectvolume"}, "role": "item"}], "container": true, "role": "item_group"}], "container": true}, {"level": 3, "type": "sep", "indent": 12, "text": [" SSS "], "extent": [10575, 10599], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["BSDF Labelled ", {"type": "code", "text": ["sss"]}], "extent": [5304, 5325], "body": [{"type": "para", "indent": 4, "text": ["Add the sss component as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["sss"]}, ", using the LPE ", {"type": "code", "text": ["C<...'sss'>.*[LO]"]}, "."], "extent": [5339, 5441]}], "container": true, "attrs": {"id": "sss"}, "role": "item"}], "container": true, "role": "item_group"}], "container": true}, {"level": 3, "type": "sep", "indent": 12, "text": [" Albedo "], "extent": [10655, 10682], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Albedo"], "extent": [6438, 6447], "body": [{"type": "para", "indent": 4, "text": ["Add the albedo output as a ", {"type": "code", "text": ["color3f"]}, " render var named ", {"type": "code", "text": ["export_basecolor"]}, ". Only available with shaders that export this information, such as the principled shader."], "extent": [6464, 6633]}], "container": true, "attrs": {"id": "albedo"}, "role": "item"}], "container": true, "role": "item_group"}], "container": true}]}, {"level": 4, "id": null, "container": true, "type": "h", "indent": 8, "text": ["Ray Level Output"], "extent": [10742, 10777], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["P (World Space)"], "extent": [5466, 5484], "body": [{"type": "para", "indent": 4, "text": ["Add the world space position as a ", {"type": "code", "text": ["point3f"]}, " render var named ", {"type": "code", "text": ["P"]}, "."], "extent": [5502, 5573]}], "container": true, "attrs": {"id": "position"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Depth (Camera Space)"], "extent": [5573, 5595], "body": [{"type": "para", "indent": 4, "text": ["Add the distance from the camera origin as a ", {"type": "code", "text": ["float"]}, " render var named ", {"type": "code", "text": ["depth"]}, "."], "extent": [5610, 5694]}], "container": true, "attrs": {"id": "depth"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Element (Raw ID)"], "extent": [5694, 5712], "body": [{"type": "para", "indent": 4, "text": ["Add the element ID as a ", {"type": "code", "text": ["float"]}, " render var named ", {"type": "code", "text": ["element"]}, "."], "extent": [5729, 5794]}], "container": true, "attrs": {"id": "element"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Prim ID"], "extent": [5794, 5803], "body": [{"type": "para", "indent": 4, "text": ["Add the primitive identifier as a ", {"type": "code", "text": ["float"]}, " render var named ", {"type": "code", "text": ["primid"]}, "."], "extent": [5819, 5893]}], "container": true, "attrs": {"id": "primid"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["UV"], "extent": [5893, 5897], "body": [{"type": "para", "indent": 4, "text": ["Add the primitive hit UV as a ", {"type": "code", "text": ["float3"]}, " render var named ", {"type": "code", "text": ["UV"]}, "."], "extent": [5909, 5976]}], "container": true, "attrs": {"id": "uv"}, "role": "item"}], "container": true, "role": "item_group"}, {"type": "include_group", "body": [{"ext": "karmastandardrendervars#dPdz", "type": "include", "indent": 12, "role": "item", "extent": [11638, 11690]}], "container": true, "role": "item_group"}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["N (Smooth Normal)"], "extent": [5976, 5995], "body": [{"type": "para", "indent": 4, "text": ["Add the primitive hit normal as a ", {"type": "code", "text": ["normal3f"]}, " render var named ", {"type": "code", "text": ["N"]}, "."], "extent": [6009, 6081]}], "container": true, "attrs": {"id": "hitN"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Ng (Geometric Normal)"], "extent": [6081, 6104], "body": [{"type": "para", "indent": 4, "text": ["Add the primitive geometric normal as a ", {"type": "code", "text": ["normal3f"]}, " render var named ", {"type": "code", "text": ["Ng"]}, "."], "extent": [6119, 6198]}], "container": true, "attrs": {"id": "hitNg"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Motion Vectors"], "extent": [6198, 6214], "body": [{"type": "para", "indent": 4, "text": ["Add the primitive motion vector as a ", {"type": "code", "text": ["vector3f"]}, " render var named ", {"type": "code", "text": ["motionvector"]}, "."], "extent": [6237, 6323]}], "container": true, "attrs": {"id": "motionvectors"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Velocity"], "extent": [6323, 6333], "body": [{"type": "para", "indent": 4, "text": ["Add the primitive velocity as a ", {"type": "code", "text": ["vector3f"]}, " render var named ", {"type": "code", "text": ["velocity"]}, "."], "extent": [6351, 6428]}], "container": true, "attrs": {"id": "velocity"}, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 4, "id": null, "container": true, "type": "h", "indent": 8, "text": ["Extra Render Vars"], "extent": [11913, 11949], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 12, "text": ["Render Vars"], "extent": [11949, 11975], "body": [{"type": "para", "indent": 16, "text": ["Use this multiparm to add custom AOVs (render vars) to the image output."], "extent": [12013, 12103]}], "container": true, "attrs": {"id": "extrarendervars"}, "role": "item"}], "container": true, "role": "item_group"}, {"type": "include_group", "body": [{"ext": "rendervar#enable", "type": "include", "indent": 12, "role": "item", "extent": [12103, 12143]}], "container": true, "role": "item_group"}, {"level": 3, "type": "sep", "indent": 12, "text": [" Render Vars "], "extent": [12143, 12175]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Name"], "extent": [3391, 3397], "body": [{"type": "para", "indent": 4, "text": ["The name of the AOV in the output image that stores the data from this rendervar."], "extent": [3411, 3498]}], "container": true, "attrs": {"id": "name"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Format"], "extent": [3498, 3506], "body": [{"type": "para", "indent": 4, "text": ["The data format that should be used when saving this image plane to the output file."], "extent": [3522, 3612]}], "container": true, "attrs": {"id": "format"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Multi-sampled"], "extent": [3948, 3963], "body": [{"type": "para", "indent": 4, "text": ["Whether the render buffer should be multisampled."], "extent": [3985, 4040]}], "container": true, "attrs": {"id": "multiSampled"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Clear value"], "extent": [4040, 4053], "body": [{"type": "para", "indent": 4, "text": ["The initial value to fill the buffer with before rendering. Usually this is ", {"type": "code", "text": ["0"]}, ", however for example for ", {"type": "code", "text": ["Pz"]}, " you might set it to ", {"type": "code", "text": ["1e17"]}, "."], "extent": [4073, 4217]}], "container": true, "attrs": {"id": "clearValue"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Data Type"], "extent": [1322, 1334], "body": [{"type": "para", "indent": 4, "text": ["The USD data type of the render variable."], "extent": [1352, 1399]}, {"type": "para", "indent": 4, "text": ["When saving to OpenEXR files, the data type is used to determine the channel names. For example, if the data type is ", {"type": "code", "text": ["color3f"]}, ", the channel names will be ", {"type": "code", "text": ["R"]}, ", ", {"type": "code", "text": ["G"]}, ", ", {"type": "code", "text": ["B"]}, ", while if the data type is ", {"type": "code", "text": ["normal3f"]}, ", the channel names will be ", {"type": "code", "text": ["x"]}, ", ", {"type": "code", "text": ["y"]}, ", ", {"type": "code", "text": ["z"]}, "."], "extent": [1399, 1652]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 4, "role": "item", "extent": [1652, 1661], "body": [{"type": "para", "indent": 8, "text": ["If you're rendering with ", {"scheme": null, "value": "/ref/utils/husk", "type": "link", "text": ["husk"], "fullpath": "/ref/utils/husk.html"}, " and want color channel names to be lower case (for example  ", {"type": "code", "text": ["r"]}, ", ", {"type": "code", "text": ["g"]}, ", ", {"type": "code", "text": ["b"]}, "), add another ", {"scheme": "Node", "value": "/nodes/lop/rendervar", "type": "link", "text": ["Render Var LOP"], "fullpath": "/nodes/lop/rendervar.html"}, " and use it to set the ", {"type": "code", "text": ["driver:parameters:aov:channel_lower_rgb"]}, " (", {"type": "code", "text": ["bool"]}, ") render var to ", {"type": "code", "text": ["true"]}, "."], "extent": [1661, 1937]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "dataType"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Source Name"], "extent": [1937, 1950], "body": [{"type": "para", "indent": 4, "text": ["Where to get the render variable contents. See ", {"type": "ui", "text": ["Source type"]}, " below."], "extent": [1970, 2045]}, {"type": "para", "indent": 4, "text": ["The renderer should look for an output with this name as the computed value for the RenderVar."], "extent": [2045, 2145]}, {"type": "tip_group", "body": [{"type": "tip", "indent": 4, "role": "item", "extent": [2145, 2154], "body": [{"type": "para", "indent": 8, "text": ["In Karma, with ", {"type": "code", "text": ["Raw"]}, " and ", {"type": "code", "text": ["Primvar"]}, " (including Cryptomatte) ", {"type": "ui", "text": ["Source type"]}, ", it\u2019s possible to prefix variable name with ", {"type": "code", "text": ["noholdouts;"]}, " to indicate that matte or background holdouts should ", {"type": "strong", "text": ["not"]}, " contribute to the AOV. For example, to output normal ", {"type": "code", "text": ["N"]}, " AOV without holdouts, enter: ", {"type": "code", "text": ["ray:noholdouts;N"]}], "extent": [2154, 2460]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "sourceName"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["Source Type"], "extent": [2460, 2473], "body": [{"type": "para", "indent": 4, "text": ["How to interpret the ", {"type": "ui", "text": ["Source name"]}, " parameter."], "extent": [2493, 2546]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": ["Raw"], "extent": [2546, 2555], "body": [{"type": "para", "indent": 8, "text": ["Pass the source name directly to the renderer. This assumes the renderer knows how to interpret the source name string. This is the default."], "extent": [2555, 2705]}], "container": true}, {"type": "dt", "indent": 4, "text": ["Primvar"], "extent": [2705, 2718], "body": [{"type": "para", "indent": 8, "text": ["The ", {"type": "ui", "text": ["Source name"]}, " is the name of primvar."], "extent": [2718, 2771]}, {"type": "para", "indent": 8, "text": ["Some renderers may use this to ensure that the primvar is provided to the renderer. Other renderers may require that a suitable material network be provided, in which case this is simply an advisory setting."], "extent": [2771, 2988]}], "container": true}, {"type": "dt", "indent": 4, "text": ["LPE"], "extent": [2988, 2997], "body": [{"type": "para", "indent": 8, "text": ["The ", {"type": "ui", "text": ["Source name"]}, " is a ", {"scheme": null, "value": "/render/lpe", "type": "link", "text": ["Light Path Expression"], "fullpath": "/render/lpe.html"}, "."], "extent": [2997, 3068]}, {"type": "para", "indent": 8, "text": ["(Some renderers may accept extensions to the OSL Light Path Expression syntax, which will necessarily be non-portable.)"], "extent": [3068, 3197]}], "container": true}, {"type": "dt", "indent": 4, "text": ["Intrinsic"], "extent": [3197, 3212], "body": [{"type": "para", "indent": 8, "text": [{"type": "strong", "text": ["Currently not implemented"]}, ". In the future, USD may provide for a portable list of baseline rendervars, such as camera depth, that would be implemented by all renderers."], "extent": [3212, 3391]}], "container": true}], "container": true}], "container": true, "attrs": {"id": "sourceType"}, "role": "item"}], "container": true, "role": "item_group"}, {"level": 3, "type": "sep", "indent": 12, "text": [" Karma "], "extent": [12474, 12500]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 16, "text": ["Pixel Filter"], "extent": [8785, 8815], "body": [{"type": "para", "indent": 20, "text": ["You can use ", {"scheme": null, "value": "/solaris/filters", "type": "link", "text": ["Solaris filter syntax"], "fullpath": "/solaris/filters.html"}, " in this parameter to filter the sample values. The default ", {"type": "code", "text": ["[\"ubox\", {}]"]}, " simply averages all the sample values within each pixel."], "extent": [8854, 9059]}], "container": true, "attrs": {"id": "beautyfilter"}, "role": "item"}, {"type": "parameters_item", "indent": 12, "text": ["Cryptomatte"], "extent": [12559, 12584], "body": [{"type": "para", "indent": 4, "text": ["Enable this to turn this image plane into Cryptomatte layer. See\n    ", {"scheme": null, "value": "/solaris/cryptomatte", "type": "link", "text": ["Cryptomatte"], "fullpath": "/solaris/cryptomatte.html"}, " for more info."], "extent": [71174, 71298]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 12, "text": ["Overlap Limit"], "extent": [12658, 12685], "body": [{"type": "para", "indent": 4, "text": ["Maximum number of IDs that can be stored in a single pixel. A value of 6 is\n    recommended."], "extent": [71386, 71484]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 12, "text": ["Manifest File"], "extent": [12763, 12790], "body": [{"type": "para", "indent": 4, "text": ["Optional external manifest file. It will be saved into same directory as\n    the render product. If this path is unspecified, the manifest will be\n    embedded into render product as metadata."], "extent": [71577, 71775]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 12, "text": ["Output Colorspace"], "extent": [8554, 8585], "body": [{"type": "para", "indent": 16, "text": ["Specify the ", {"scheme": null, "value": "/io/ocio", "type": "link", "text": ["OCIO"], "fullpath": "/io/ocio.html"}, " color output space for the component."], "extent": [8616, 8699]}], "container": true, "attrs": {"id": "outputcs"}, "role": "item"}], "container": true, "role": "item_group"}]}]}, {"level": 3, "id": "filters", "container": true, "type": "h", "indent": 4, "text": ["Filters"], "extent": [12925, 12955], "body": [{"level": 3, "type": "sep", "indent": 8, "text": [" Image Filters "], "extent": [12955, 12986]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 8, "text": ["Denoiser"], "extent": [12986, 13005], "body": [{"type": "para", "indent": 12, "text": ["Choose a denoiser to run on the finished image output, or ", {"type": "ui", "text": ["No Denoiser"]}, ". This utility currently supports ", {"scheme": null, "value": "https://openimagedenoise.github.io", "type": "link", "text": ["Intel Open Image Denoise"], "exists": true}, " (included with Houdini) and the ", {"scheme": null, "value": "https://developer.nvidia.com/optix-denoiser", "type": "link", "text": ["NVIDIA OptiX Denoiser"], "exists": true}, " (must be installed separately). You must be on a supported platform and have the chosen denoising library installed for this to work."], "extent": [13043, 13459]}, {"type": "para", "indent": 12, "text": ["The NVIDIA OptiX Denoiser only works with NVIDIA cards. It is now included with the NVIDIA driver (version 435 or later)."], "extent": [13459, 13594]}], "container": true, "attrs": {"id": "denoise"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Use Albedo"], "extent": [13594, 13614], "body": [{"type": "para", "indent": 12, "text": ["Some denoising libraries can use albedo to get a better sense of the image, guiding how and where it reduces noise."], "extent": [13642, 13771]}], "container": true, "attrs": {"id": "usealbedo"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Use N Input"], "extent": [13771, 13792], "body": [{"type": "para", "indent": 12, "text": ["Some denoising libraries can use normals to get a better sense of the image, guiding how and where it reduces noise."], "extent": [13820, 13949]}], "container": true, "attrs": {"id": "useninput"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["AOVS"], "extent": [14027, 14041], "body": [{"type": "para", "indent": 12, "text": ["Space-separated list of AOVs to run the denoiser on."], "extent": [14041, 14107]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Tone Map"], "extent": [14107, 14125], "body": [{"type": "para", "indent": 12, "text": ["The basic idea behind tone mapping is the conversion from HDR real world luminances to LDR display values, i.e. for making images displayable on monitors. Another aspect is to simulate a particular film look. Film material is designed to have a certain ", {"type": "q", "text": ["response"]}, " to light to enhance contrast and colors, represented as a characteristic curve. A filmic tone mapping curve is subdivided into toe, shoulder and linear sections for an image\u2019s dark, bright, and mid tones. Houdini provides several common operators for filmic tone mapping and each operator applies a specific S-shaped tone mapping curve."], "extent": [14151, 14765]}, {"type": "bullet_group", "body": [{"blevel": 14, "type": "bullet", "indent": 12, "text": [{"type": "ui", "text": ["Reinhard"]}, ", ", {"type": "ui", "text": ["Ward"]}, " and ", {"type": "ui", "text": ["Aces"]}, " don\u2019t provide any further parameters to adjust the toe, shoulder and linear sections."], "extent": [14765, 14901]}, {"blevel": 14, "type": "bullet", "indent": 12, "text": [{"type": "ui", "text": ["Hable"]}, ", ", {"type": "ui", "text": ["Hable2"]}, " and ", {"type": "ui", "text": ["Unreal"]}, ", however, have specific parameters for customizing the curve."], "extent": [14901, 15015]}], "container": true}, {"type": "tip_group", "body": [{"type": "tip", "indent": 12, "role": "item", "extent": [15015, 15032], "body": [{"type": "para", "indent": 16, "text": ["The external links below provide more information about tone mapping"], "extent": [15032, 15118]}, {"type": "bullet_group", "body": [{"blevel": 18, "type": "bullet", "indent": 16, "text": [{"scheme": null, "value": "https://docs.unrealengine.com/4.26/en-US/RenderingAndGraphics/PostProcessEffects/ColorGrading/", "type": "link", "text": ["Unreal"], "exists": true}], "extent": [15118, 15240]}, {"blevel": 18, "type": "bullet", "indent": 16, "text": [{"scheme": null, "value": "https://docs.arnoldrenderer.com/display/A5AFHUG/Imager+Tonemap?desktop=true&amp&macroName=multiexcerpthttp://filmicworlds.com/blog/filmic-tonemapping-with-piecewise-power-curves/", "type": "link", "text": ["Hable2"], "exists": true}], "extent": [15240, 15446]}, {"blevel": 18, "type": "bullet", "indent": 16, "text": [{"scheme": null, "value": "https://knarkowicz.wordpress.com/2016/01/06/aces-filmic-tone-mapping-curve/", "type": "link", "text": ["ACES"], "exists": true}], "extent": [15446, 15548]}], "container": true}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "tonemap"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Tonemap Curve"], "extent": [15548, 15571], "body": [{"type": "para", "indent": 12, "text": ["Tone map curves apply to the ", {"type": "ui", "text": ["Reinhard"]}, ", ", {"type": "ui", "text": ["Unreal"]}, ", ", {"type": "ui", "text": ["Aces"]}, " and ", {"type": "ui", "text": ["Hable"]}, " operators. The curve is a visual representation of the mathematical model of each operator. You can fine-tune tone mapping through the curve\u2019s control points. "], "extent": [15602, 15853]}], "container": true, "attrs": {"id": "tonemapcurve"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["AOVs"], "extent": [15853, 15867], "body": [{"type": "para", "indent": 12, "text": ["Space-separated list of AOVs that will be affected by the chosen ", {"type": "ui", "text": ["Tone Map"]}, " operator."], "extent": [15898, 15999]}], "container": true, "attrs": {"id": "tonemap_aovs"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Toe"], "extent": [15999, 16012], "body": [{"type": "para", "indent": 12, "text": ["This parameter applies to the ", {"type": "ui", "text": ["Hable"]}, ", ", {"type": "ui", "text": ["Hable2"]}, " and ", {"type": "ui", "text": ["Unreal"]}, " operators and ranges between ", {"type": "code", "text": ["0"]}, " and ", {"type": "code", "text": ["1"]}, ". The default values for ", {"type": "ui", "text": ["Hable"]}, " and ", {"type": "ui", "text": ["Hable2"]}, " is ", {"type": "code", "text": ["0.5"]}, ". For ", {"type": "ui", "text": ["Unreal"]}, ", the default value is ", {"type": "code", "text": ["0.55"]}, ". The value controls the strength (curvature) of the toe segment in dark areas. Higher values create a darker image, smaller values brighten the dark tones."], "extent": [16042, 16422]}], "container": true, "attrs": {"id": "tonemap_toe"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Shoulder"], "extent": [16422, 16440], "body": [{"type": "para", "indent": 12, "text": ["This parameter applies to the ", {"type": "ui", "text": ["Hable"]}, ", ", {"type": "ui", "text": ["Hable2"]}, " and ", {"type": "ui", "text": ["Unreal"]}, " operators and ranges between ", {"type": "code", "text": ["0"]}, "and ", {"type": "code", "text": ["1"]}, ". The default values for ", {"type": "ui", "text": ["Hable"]}, " and ", {"type": "ui", "text": ["Hable2"]}, " is ", {"type": "code", "text": ["0.5"]}, ". For ", {"type": "ui", "text": ["Unreal"]}, ", the default value is ", {"type": "code", "text": ["0.26"]}, ". ", {"type": "ui", "text": ["Shoulder"]}, " controls to curve\u2019s amount of curvature for bright tone values. The value affects where the shoulder curve starts in the graph: a value of ", {"type": "code", "text": ["1"]}, " means that the shoulder starts exactly where the toe ends."], "extent": [16475, 16914]}], "container": true, "attrs": {"id": "tonemap_shoulder"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Slope"], "extent": [16914, 16929], "body": [{"type": "para", "indent": 12, "text": ["This parameter applies to the ", {"type": "ui", "text": ["Unreal"]}, " operator and ranges between ", {"type": "code", "text": ["0"]}, " and ", {"type": "code", "text": ["1"]}, ". The default value is ", {"type": "code", "text": ["0.88"]}, ". Controls the tone mapping curve\u2019s steepness, where higher settings (steeper curve) make the image darker and increase contrast; smaller values brighten the image and make it pale."], "extent": [16961, 17265]}], "container": true, "attrs": {"id": "tonemap_slope"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Linear"], "extent": [17265, 17281], "body": [{"type": "para", "indent": 12, "text": ["This parameter applies to the ", {"type": "ui", "text": ["Hable"]}, " operator and ranges between ", {"type": "code", "text": ["0"]}, " and ", {"type": "code", "text": ["2"]}, ". The default value is ", {"type": "code", "text": ["0.3"]}, ". Tones in the linear section should not (or hardly) change during the tone mapping process and represent the image\u2019s original tones. The ", {"type": "ui", "text": ["Linear"]}, " value describes the distance between toe and shoulder. Higher values mean that the tow and shoulder sections become smaller, while more tones remain unchanged: the overall curve becomes more linear."], "extent": [17314, 17782]}], "container": true, "attrs": {"id": "tonemap_linear"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Linear Angle"], "extent": [17782, 17804], "body": [{"type": "para", "indent": 12, "text": ["This parameter applies to the ", {"type": "ui", "text": ["Hable"]}, " operator and ranges between ", {"type": "code", "text": ["0"]}, " and ", {"type": "code", "text": ["1"]}, ". The default value is ", {"type": "code", "text": ["0.1"]}, ". Here you control the slope of the linear part of the tone mapping curve."], "extent": [17842, 18037]}], "container": true, "attrs": {"id": "tonemap_linearangle"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Toe Length"], "extent": [18037, 18057], "body": [{"type": "para", "indent": 12, "text": ["This parameter applies to the ", {"type": "ui", "text": ["Hable2"]}, " operator and ranges between ", {"type": "code", "text": ["0"]}, " and ", {"type": "code", "text": ["1"]}, ".  The default value is ", {"type": "code", "text": ["0.5"]}, ". A small value creates a short toe section that quickly transitions into the linear section. A value of ", {"type": "code", "text": ["0"]}, " eliminates the toe, and value of ", {"type": "code", "text": ["1"]}, " means the toe takes up half the curve. Note that there are two ways to disable the toe: you can either set ", {"type": "ui", "text": ["Toe Length"]}, " or ", {"type": "ui", "text": ["Toe"]}, " to ", {"type": "code", "text": ["0"]}, "."], "extent": [18093, 18502]}], "container": true, "attrs": {"id": "tonemap_toelength"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Shoulder Length"], "extent": [18502, 18527], "body": [{"type": "para", "indent": 12, "text": ["This parameter applies to the ", {"type": "ui", "text": ["Hable2"]}, " operator and ranges between ", {"type": "code", "text": ["0"]}, " and ", {"type": "code", "text": ["1"]}, ".  The default value is ", {"type": "code", "text": ["0.5"]}, ". ", {"type": "ui", "text": ["Shoulder Length"]}, " describes how many F stops you want to add to the dynamic range of the curve. Here you control the transition point from the linear section to the shoulder section."], "extent": [18568, 18877]}], "container": true, "attrs": {"id": "tonemap_shoulderlength"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Shoulder Angle"], "extent": [18877, 18901], "body": [{"type": "para", "indent": 12, "text": ["This parameter applies to the ", {"type": "ui", "text": ["Hable2"]}, " operator and ranges between ", {"type": "code", "text": ["0"]}, " and ", {"type": "code", "text": ["1"]}, ".  The default value is ", {"type": "code", "text": ["1"]}, ". Here you control how much overshoot you want to add the curve\u2019s shoulder."], "extent": [18941, 19137]}], "container": true, "attrs": {"id": "tonemap_shoulderangle"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["OCIO"], "extent": [19137, 19151], "body": [{"type": "para", "indent": 12, "text": [{"scheme": null, "value": "/io/ocio", "type": "link", "text": ["OCIO"], "fullpath": "/io/ocio.html"}, " image filters can be added to various render vars/image planes. "], "extent": [19174, 19268]}], "container": true, "attrs": {"id": "ocio"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Enable"], "extent": [19268, 19284], "body": [{"type": "para", "indent": 12, "text": ["Enables the OCIO image filter defined below."], "extent": [19313, 19371]}], "container": true, "attrs": {"id": "enableocio"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Planes"], "extent": [19371, 19387], "body": [{"type": "para", "indent": 12, "text": ["The render var names to which the OCIO image filter will be applied."], "extent": [19416, 19498]}], "container": true, "attrs": {"id": "ocioplanes"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Output Space"], "extent": [19498, 19520], "body": [{"type": "para", "indent": 12, "text": ["Specify the OCIO color output space the image filter will apply."], "extent": [19554, 19632]}], "container": true, "attrs": {"id": "ociooutputspace"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Input Space"], "extent": [19632, 19653], "body": [{"type": "para", "indent": 12, "text": ["In most cases this should be left at ", {"type": "code", "text": ["data"]}, ". There may be some strange case where the source of the AOV is already in a defined color space, in which case you can specify the source space here."], "extent": [19698, 19905]}], "container": true, "attrs": {"id": "ocioinputspace"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Looks"], "extent": [19905, 19920], "body": [{"type": "para", "indent": 12, "text": ["Space-separated list of looks to apply to the finished image. A ", {"type": "q", "text": ["look"]}, " is a named OCIO color transform, usually intended to achieve an artistic effect. See the OCIO documentation for more information."], "extent": [19948, 20163]}], "container": true, "attrs": {"id": "ociolooks"}, "role": "item"}], "container": true, "role": "item_group"}, {"level": 3, "type": "sep", "indent": 8, "text": [" Sample Filters "], "extent": [20163, 20194]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 8, "text": ["Color Limits"], "extent": [20194, 20217], "body": [{"type": "para", "indent": 12, "text": ["A color limit clamps the value a shading sample is allowed to contribute to an LPE image plane, to reduce appearance of ", {"type": "q", "text": ["fireflies"]}, " caused by undersampling of extremely bright light sources. This multiparm lets you apply separate limits to different sets of render vars."], "extent": [20247, 20531]}], "container": true, "attrs": {"id": "colorlimits"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Enable"], "extent": [20531, 20547], "body": [{"type": "para", "indent": 12, "text": ["Enables the color limit sample filter defined below."], "extent": [20583, 20649]}], "container": true, "attrs": {"id": "enablecolorlimits"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Planes"], "extent": [20649, 20665], "body": [{"type": "para", "indent": 12, "text": ["A space-separated list of AOV names to which this color limit will be applied."], "extent": [20700, 20792]}], "container": true, "attrs": {"id": "colorlimitplanes"}, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Limit"], "extent": [20792, 20807], "body": [{"type": "para", "indent": 12, "text": ["The maximum value a shading sample is allowed to contribute to these AOVs."], "extent": [20841, 20930]}], "container": true, "attrs": {"id": "colorlimitlimit"}, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 3, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Aspect Ratio"], "extent": [20930, 20955], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Aspect Ratio Conform Policy"], "extent": [2849, 2882], "body": [{"type": "para", "indent": 8, "text": ["What to do if the aspect ratio of the output image (", {"type": "ui", "text": ["Resolution"]}, " width divided by height) doesn\u2019t match the aspect ratio of the camera aperture (controlled by attributes on the camera). This allows a standard renderer to do something reasonable when you switch between cameras."], "extent": [2921, 3210]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 8, "text": ["Expand Aperture"], "extent": [3210, 3235], "body": [{"type": "para", "indent": 12, "text": ["If necessary, expand the camera aperture to match the image."], "extent": [3235, 3309]}], "container": true}, {"type": "dt", "indent": 8, "text": ["Crop Aperture"], "extent": [3309, 3332], "body": [{"type": "para", "indent": 12, "text": ["If necessary, crop the camera aperture to match the image."], "extent": [3332, 3404]}], "container": true}, {"type": "dt", "indent": 8, "text": ["Adjust Aperture Width"], "extent": [3404, 3435], "body": [{"type": "para", "indent": 12, "text": ["If necessary, change the camera aperture width to match the image."], "extent": [3435, 3515]}], "container": true}, {"type": "dt", "indent": 8, "text": ["Adjust Aperture Height"], "extent": [3515, 3547], "body": [{"type": "para", "indent": 12, "text": ["If necessary, change the camera aperture height to match the image."], "extent": [3547, 3628]}], "container": true}, {"type": "dt", "indent": 8, "text": ["Adjust Pixel Aspect Ratio"], "extent": [3628, 3663], "body": [{"type": "para", "indent": 12, "text": ["Change the aspect ratio of the image to match the camera."], "extent": [3663, 3734]}], "container": true}], "container": true}], "container": true, "attrs": {"id": "aspectRatioConformPolicy"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Data Window NDC"], "extent": [3734, 3755], "body": [{"type": "para", "indent": 8, "text": ["Directs the renderer to only render within this window of the entire output image. You specify the window as ", {"type": "code", "text": ["minX, minY, maxX, maxY"]}, ", where each number is a normalized value from ", {"type": "code", "text": ["0"]}, " to ", {"type": "code", "text": ["1"]}, ". ", {"type": "code", "text": ["0, 0"]}, " is the bottom left, ", {"type": "code", "text": ["1, 1"]}, " is the top right, ", {"type": "code", "text": ["0.5, 0.5"]}, " is the center, and so on. The default is ", {"type": "code", "text": ["0, 0, 1, 1"]}, " (no cropping). Note that you can use ", {"type": "em", "text": ["negative"]}, " values. For example, ", {"type": "code", "text": ["-0.1, -0.1, 1.1, 1.1"]}, " will give you 10% overscan on each side."], "extent": [3783, 4234]}, {"type": "para", "indent": 8, "text": ["You can use this window to temporarily ", {"type": "em", "text": ["crop"]}, " the render to a smaller region, for testing purposes."], "extent": [4234, 4343]}, {"type": "para", "indent": 8, "text": ["Pixels are only rendered if they are ", {"type": "em", "text": ["fully"]}, " inside the window."], "extent": [4343, 4416]}, {"type": "para", "indent": 8, "text": ["The normalized coordinates map to the image ", {"type": "em", "text": ["after"]}, " any adjustments by the ", {"type": "ui", "text": ["Aspect ratio conform policy"]}, "."], "extent": [4416, 4533]}], "container": true, "attrs": {"id": "dataWindowNDC"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Pixel Aspect Ratio"], "extent": [4533, 4557], "body": [{"type": "para", "indent": 8, "text": ["The aspect ratio (width/height) of image ", {"type": "em", "text": ["pixels"]}, " (", {"type": "em", "text": ["not"]}, " the image itself).\n        The default is ", {"type": "code", "text": ["1.0"]}, ", indicating square pixels."], "extent": [4588, 4730]}], "container": true, "attrs": {"id": "pixelAspectRatio"}, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 3, "id": null, "container": true, "type": "h", "indent": 4, "text": ["Meta Data"], "extent": [21115, 21137], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 8, "text": ["Artist"], "extent": [21137, 21154], "body": [{"type": "para", "indent": 4, "text": ["The name of the person, department, or studio that created the image file. The node will set this field on the output image if the image format supports metadata (for example, ", {"type": "code", "text": [".exr"]}, ")."], "extent": [3340, 3530]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Comment"], "extent": [21224, 21241], "body": [{"type": "para", "indent": 4, "text": ["An arbitrary comment, for example a description of the purpose of the output image. The node will set this field on the output image if the image format supports metadata (for example, ", {"type": "code", "text": [".exr"]}, ")."], "extent": [3582, 3781]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["Hostname"], "extent": [21313, 21331], "body": [{"type": "para", "indent": 4, "text": ["The name of the computer that generated this the output file. The node will set this field on the output image if the image format supports metadata (for example, ", {"type": "code", "text": [".exr"]}, ")."], "extent": [3835, 4012]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 8, "text": ["EXR Compression"], "extent": [21404, 21429], "body": [{"type": "para", "indent": 4, "text": ["Sets the compression for saved OpenEXR files. When saving multi-part OpenEXR files, you can specify compression per AOV through a ", {"scheme": "Node", "value": "/nodes/lop/rendervar", "type": "link", "text": ["Render Var LOP"], "fullpath": "/nodes/lop/rendervar.html"}, "."], "extent": [5230, 5402]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}]}, {"level": 2, "id": "deep_output_tab", "container": true, "type": "h", "indent": 0, "text": ["Deep Output"], "extent": [21514, 21550], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 0, "text": ["Deep Camera Map"], "extent": [21550, 21568], "body": [{"type": "para", "indent": 4, "text": ["Generate a deep camera map image recording depth."], "extent": [21582, 21637]}, {"type": "para", "indent": 4, "text": ["Deep camera maps are rendered images, where semi-transparent areas (such as volumes) between the camera and the nearest opaque surface are stored with depth information. Each pixel in the image is represented as a curve describing how the transparency value changes across the depth of the scene. This allows you to composite rendered images and have the semi-transparent areas blend correctly according to their depth."], "extent": [21637, 22062]}], "container": true, "attrs": {"id": "dcm"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["DCM Filename"], "extent": [22062, 22076], "body": [{"type": "para", "indent": 4, "text": ["The filename to save the deep camera map image to (this should be an ", {"type": "code", "text": [".exr"]}, " file)."], "extent": [22098, 22186]}, {"type": "para", "indent": 4, "text": ["Include ", {"type": "code", "text": ["$F"]}, " in the file name to insert the frame number. This is necessary when rendering animation. See ", {"scheme": null, "value": "/render/expressions", "type": "link", "text": ["expressions in file names"], "fullpath": "/render/expressions.html"}, " for more information."], "extent": [22186, 22367]}], "container": true, "attrs": {"id": "dcmfilename"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["DCM Render Vars"], "extent": [22367, 22384], "body": [{"type": "para", "indent": 4, "text": ["Space separated list of RenderVar ", {"type": "em", "text": ["prim paths"]}, " (", {"type": "em", "text": ["not"]}, " a list of AOV names). These must be the fully qualified path to the RenderVar prim and the render var name. You can use patterns to match multiple prims. The default is ", {"type": "code", "text": ["/Render/Products/Vars/*"]}, ", which matches all prims in the branch where Houdini usually creates RenderVar prims. You can also leave this field empty to omit all RenderVars and only include alpha and depth planes (like a Deep Shadow Map)."], "extent": [22402, 22867]}], "container": true, "attrs": {"id": "dcmvars"}, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["DCM Compression"], "extent": [22867, 22884], "body": [{"type": "para", "indent": 4, "text": ["Compression value between ", {"type": "code", "text": ["0"]}, " and ", {"type": "code", "text": ["10"]}, ". Used to limit the number of samples\n    which are stored in a lossy compression mode for volume samples.  The\n    compression parameter determines the maximum possible error in scalar\n    channels for each sample. For compression greater than ", {"type": "code", "text": ["0"]}, ", the following\n    relationship holds: ", {"type": "code", "text": ["Error = 1/(2^(10-compression))"]}], "extent": [5639, 6003]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["DCM Of Size"], "extent": [22946, 22959], "body": [{"type": "para", "indent": 4, "text": ["Opacity is usually computed as a full-color value and stored as such. To\n    cut down on file size, if full color is not needed, this settings can be\n    used to store a monochromatic version of the full color value.\n    Set this value to ", {"type": "code", "text": ["1"]}, " for monochrome, ", {"type": "code", "text": ["3"]}, " for full color."], "extent": [6071, 6355]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 0, "text": ["DCM Z-Bias"], "extent": [23016, 23028], "body": [{"type": "para", "indent": 4, "text": ["Used in compression to merge together samples which are closer than the\n    given threshold. Samples that are closer together than this bias value are\n    merged into a single sample whose z-front and z-back span encompasses all\n    the merged samples."], "extent": [6421, 6679]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 2, "id": "advanced_tab", "container": true, "type": "h", "indent": 0, "text": ["Advanced"], "extent": [23085, 23115], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Set as Default Render Settings Prim"], "extent": [23115, 23157], "body": [{"type": "para", "indent": 8, "text": ["A layer in USD can define a default render settings primitive for ", {"type": "code", "text": ["husk"]}, " or other tools to use when rendering."], "extent": [23194, 23314]}], "container": true, "attrs": {"id": "setlayerrendersettings"}, "role": "item"}], "container": true, "role": "item_group"}, {"level": 3, "id": "advanced_sampling_tab", "container": true, "type": "h", "indent": 4, "text": ["Sampling"], "extent": [23314, 23359], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Convergence Mode"], "extent": [23359, 23382], "body": [{"type": "para", "indent": 4, "text": ["When set to Path Traced, maximum of 1 indirect ray is generated per\n    bounce. When set to Automatic, the number of indirect rays is calculated\n    based on initial noise estimate, target noise threshold, and the maximum\n    number of camera rays. Also note that under Automatic mode, number of\n    samples for direct lighting is adjusted based on noise estimate as well."], "extent": [7295, 7673]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}, {"level": 3, "type": "sep", "indent": 4, "text": [" Primary Samples "], "extent": [23454, 23482]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Pixel Oracle"], "extent": [23482, 23501], "body": [{"type": "para", "indent": 4, "text": ["When rendering, a Pixel Oracle tells karma which pixels need additional\n    sampling and which pixels are converged. This parameter tells karma which oracle to use."], "extent": [10472, 10642]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["uniform"]}], "extent": [10642, 10657], "body": [{"type": "para", "indent": 8, "text": ["Uniformly distribute rays to each pixel.  Each pixel will always get the same number of ray-samples."], "extent": [10657, 10767]}], "container": true}, {"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["variance"]}], "extent": [10767, 10783], "body": [{"type": "para", "indent": 8, "text": ["Distribute rays based on variance in the rendered image."], "extent": [10783, 10849]}], "container": true}], "container": true}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Minimum Samples"], "extent": [23568, 23589], "body": [{"type": "para", "indent": 8, "text": ["The minimum number of camera rays (primary samples) for each pixel."], "extent": [23621, 23698]}], "container": true, "attrs": {"id": "oracle_minsamples"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Plane"], "extent": [23698, 23709], "body": [{"type": "para", "indent": 8, "text": ["The AOV to use to measure variance."], "extent": [23736, 23781]}], "container": true, "attrs": {"id": "oracle_plane"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Variance Threshold"], "extent": [23781, 23805], "body": [{"type": "para", "indent": 8, "text": ["The amount of variance that triggers more rays."], "extent": [23835, 23892]}], "container": true, "attrs": {"id": "oracle_variance"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Random Seed"], "extent": [23892, 23909], "body": [{"type": "para", "indent": 8, "text": ["Variance sampling involves some randomness. You can change this number to get slightly different results."], "extent": [23934, 24049]}], "container": true, "attrs": {"id": "randomseed"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["OCIO Transform"], "extent": [24049, 24069], "body": [{"type": "para", "indent": 8, "text": ["Whether to apply an OCIO transform to the pixels before measuring variance."], "extent": [24099, 24184]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 8, "text": ["Disabled"], "extent": [24184, 24202], "body": [{"type": "para", "indent": 12, "text": ["Do not apply an OCIO transform."], "extent": [24202, 24247]}], "container": true}, {"type": "dt", "indent": 8, "text": ["Display View"], "extent": [24247, 24269], "body": [{"type": "para", "indent": 12, "text": ["Transform to the color space of a display."], "extent": [24269, 24325]}], "container": true}, {"type": "dt", "indent": 8, "text": ["Explicit"], "extent": [24325, 24343], "body": [{"type": "para", "indent": 12, "text": ["Transform to a named color space."], "extent": [24343, 24390]}], "container": true}], "container": true}], "container": true, "attrs": {"id": "oracle_ociomode"}, "role": "item"}], "container": true, "role": "item_group"}, {"level": 3, "type": "sep", "indent": 4, "text": [" Secondary Samples "], "extent": [24390, 24420]}, {"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Noise Level"], "extent": [24420, 24438], "body": [{"type": "para", "indent": 4, "text": ["Noise threshold to determine the number of indirect rays cast for indirect bounce when the Convergence Mode is set to ", {"type": "q", "text": ["Automatic"]}, ". Decreasing this threshold (for example, to ", {"type": "code", "text": ["0.001"]}, ") will theoretically send more indirect rays and decrease noise, however the ", {"type": "q", "text": ["extra"]}, " rays will likely be cancelled out by the ", {"type": "ui", "text": ["Max Ray Samples"]}, " parameter. The correct way to decrease noise is to increase the number of samples per pixel, rather than change this threshold."], "extent": [67035, 67495]}, {"type": "para", "indent": 4, "text": ["If you are using ", {"type": "ui", "text": ["Variance Pixel Oracle"]}, ", you should set the same value for both threshold parameters. Setting the oracle\u2019s threshold lower may make the indirect component reach its threshold sooner and cast fewer indirect rays, but the oracle decides to cast more expensive camera rays because the amount of final noise in the beauty pass is higher than the oracle\u2019s threshold."], "extent": [67495, 67881]}], "container": true, "attrs": {"id": "varianceaa_thresh"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Enable Indirect Guiding"], "extent": [24542, 24571], "body": [{"type": "para", "indent": 4, "text": ["When turned on, Karma does a pre-render to roughly estimate of the light in the scene, and uses that to guide indirect diffuse rays, rather than just relying on the BSDF sampling distribution. This can improve ", {"type": "q", "text": ["difficult"]}, " lighting (for example, caustics, and mostly indirect lighting), but can make ", {"type": "q", "text": ["easy"]}, " lighting noisier. Before using this, you can try rendering direct and indirect AOVs to see where the noise is. If the noise is mostly caused by the direct lighting, there\u2019s no point in turning on path guiding."], "extent": [21791, 22312]}, {"type": "note_group", "body": [{"type": "note", "indent": 4, "role": "item", "extent": [22312, 22322], "body": [{"type": "para", "indent": 8, "text": ["When rendering to ", {"scheme": null, "value": "/mplay/index", "type": "link", "text": ["Mplay"], "fullpath": "/mplay/index.html"}, ", the user can click to focus on an area to render. Click to focus is not available with ", {"type": "ui", "text": ["Enable Indirect Guiding"]}, " turned on."], "extent": [22322, 22497]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "attrs": {"id": "guiding_enable"}, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 3, "id": "checkpointing_tab", "container": true, "type": "h", "indent": 4, "text": ["Checkpointing"], "extent": [25151, 25197], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Output Checkpoint Files"], "extent": [25197, 25227], "body": [{"type": "para", "indent": 8, "text": ["When this is on, Karma will periodically write out image tile data to a checkpoint file.  If the process is terminated before completing the render, you can resume it by turning on ", {"type": "ui", "text": ["Resume from Checkpoint"]}, " and restarting."], "extent": [25258, 25491]}], "container": true, "attrs": {"id": "outputcheckpoint"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Checkpoint File"], "extent": [25491, 25512], "body": [{"type": "para", "indent": 8, "text": ["When ", {"type": "ui", "text": ["Output checkpoint files"]}, " is on, the name of the checkpoint file to write to. The default (", {"type": "code", "text": ["$HIP/render/$HIPNAME.$OS.$F4.checkpoint"]}, ") puts the checkpoint file inside a ", {"type": "code", "text": ["render"]}, " directory next to the current scene file, and includes the base name of the current scene file (", {"type": "code", "text": ["$HIPNAME"]}, "), this node\u2019s name (", {"type": "code", "text": ["$OS"]}, "), and the render frame (", {"type": "code", "text": ["$F"]}, ") in the filename to help avoid two processes trying to use the same checkpoint file at the same time."], "extent": [25538, 25995]}], "container": true, "attrs": {"id": "productName"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Save Frequency"], "extent": [25995, 26015], "body": [{"type": "para", "indent": 8, "text": ["When ", {"type": "ui", "text": ["Output checkpoint files"]}, " is on, Karma waits this number of seconds between writing out a checkpoint file. The default is ", {"type": "code", "text": ["60"]}, "."], "extent": [26043, 26187]}], "container": true, "attrs": {"id": "savefrequency"}, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Resume From Checkpoint"], "extent": [26187, 26215], "body": [{"type": "para", "indent": 8, "text": ["If this is on and you start a render and the renderer notices there is a valid checkpoint file, it will try to resume rendering from that checkpoint. If you want to restart the render from the beginning, you can turn this off or just delete the checkpoint file(s)."], "extent": [26236, 26511]}], "container": true, "attrs": {"id": "resume"}, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 3, "id": "tiles_and_caching_tab", "container": true, "type": "h", "indent": 4, "text": ["Buckets and Caching"], "extent": [26511, 26567], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Image Mode"], "extent": [26567, 26584], "body": [{"type": "para", "indent": 4, "text": ["Determines how the image will be rendered."], "extent": [18721, 18773]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["progressive"]}], "extent": [18773, 18792], "body": [{"type": "para", "indent": 8, "text": ["The entire image will be progressively rendered, so the whole image resolves at the same time.  This mode gives you a sense of what the whole image will look like without waiting for the render to complete."], "extent": [18792, 19007]}], "container": true}, {"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["bucket"]}], "extent": [19007, 19021], "body": [{"type": "para", "indent": 8, "text": ["Each bucket renders to completion before advancing to the next bucket.  This mode  lets you see what the final quality will be like without waiting for the whole image to render. This mode isn\u2019t available with ", {"type": "ui", "text": ["Enable Indirect Guiding"]}, " turned on."], "extent": [19021, 19279]}], "container": true}], "container": true}, {"type": "note_group", "body": [{"type": "note", "indent": 4, "role": "item", "extent": [19279, 19289], "body": [{"type": "para", "indent": 8, "text": ["When rendering for IPR, Karma will use progressive rendering until the IPR preview passes are complete."], "extent": [19289, 19402]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Progressive Passes"], "extent": [26649, 26673], "body": [{"type": "para", "indent": 4, "text": ["When rendering in bucket mode (see ", {"type": "code", "text": ["imagemode"]}, "), this is the number of progressive passes over the image to perform before switching to bucket mode."], "extent": [19492, 19646]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Bucket Size"], "extent": [26746, 26763], "body": [{"type": "para", "indent": 4, "text": ["Karma breaks down an image into multiple buckets for rendering. This is the side length (in pixels) of the square bucket. The default is 32, specifying a 32 pixel x 32 pixel bucket. Threads operate at the bucket level, so it might be useful to lower the bucket size if there are only a few buckets that are particularly expensive. That way the expensive areas can be divided across more threads."], "extent": [16859, 17260]}, {"type": "para", "indent": 4, "text": ["For example, if the image is mostly empty, but there\u2019s a distant object that fits within single 32 x 32 bucket, then that object will only be rendered using 1 thread. If you switch to a 16 x 16 bucket, then the object might be split across 4 buckets and have 4 threads working on it."], "extent": [17260, 17549]}, {"type": "para", "indent": 4, "text": ["Ideally changing the bucket size doesn\u2019t change the results, but Karma measures variance across pixels within the current bucket, so if you set it to a low value, for example 4, Karma only has ", {"type": "code", "text": ["4 x 4 = 16"]}, " pixels to look at, so Karma will tend to make very poor variance estimates. This can show up as black pixels, where pixel rendering terminated prematurely due to a bad variance estimate."], "extent": [17549, 17947]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Bucket Order"], "extent": [26829, 26847], "body": [{"type": "para", "indent": 4, "text": ["Specifies which buckets are rendered first. Values can be:"], "extent": [18025, 18089]}, {"type": "dt_group", "body": [{"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["middle"]}], "extent": [18089, 18103], "body": [{"type": "para", "indent": 8, "text": ["Buckets start from the middle of the image."], "extent": [18103, 18155]}], "container": true}, {"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["top"]}], "extent": [18155, 18166], "body": [{"type": "para", "indent": 8, "text": ["Buckets at the top of the image are rendered first."], "extent": [18166, 18226]}], "container": true}, {"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["bottom"]}], "extent": [18226, 18240], "body": [{"type": "para", "indent": 8, "text": ["Buckets at the bottom of the image are rendered first."], "extent": [18240, 18303]}], "container": true}, {"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["left"]}], "extent": [18303, 18315], "body": [{"type": "para", "indent": 8, "text": ["Buckets at the left side of the image are rendered first."], "extent": [18315, 18381]}], "container": true}, {"type": "dt", "indent": 4, "text": [{"type": "code", "text": ["right"]}], "extent": [18381, 18394], "body": [{"type": "para", "indent": 8, "text": ["Buckets at the right side of the image are rendered first."], "extent": [18394, 18462]}], "container": true}], "container": true}, {"type": "note_group", "body": [{"type": "note", "indent": 4, "role": "item", "extent": [18462, 18472], "body": [{"type": "para", "indent": 8, "text": ["When rendering to ", {"scheme": null, "value": "/mplay/index", "type": "link", "text": ["Mplay"], "fullpath": "/mplay/index.html"}, ", the user can click to focus on an area to render. Click to focus is not available with ", {"type": "ui", "text": ["Enable Indirect Guiding"]}, " turned on."], "extent": [18472, 18647]}], "container": true}], "container": true, "role": "item_group"}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Cache Limit"], "extent": [26914, 26931], "body": [{"type": "para", "indent": 4, "text": ["Whether to use a fixed size cache (", {"type": "code", "text": ["karma:global:cachesize"]}, ") or whether to use a proportion of physical memory (", {"type": "code", "text": ["karma:global:cacheratio"]}, ")"], "extent": [11509, 11653]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Cache Memory Ratio"], "extent": [27000, 27024], "body": [{"type": "para", "indent": 4, "text": ["The proportion of physical memory Karma will use for its unified cache."], "extent": [11736, 11813]}, {"type": "para", "indent": 4, "text": ["For example, with the default ", {"type": "code", "text": ["vm_cacheratio"]}, " of ", {"type": "code", "text": ["0.25"]}, " and 16 Gb of\n    physical memory, Karma will use 4 Gb for its unified cache."], "extent": [11813, 11951]}, {"type": "para", "indent": 4, "text": ["The unified cache stores dynamic, unloadable data used by the render\n    including the following:"], "extent": [11951, 12054]}, {"type": "bullet_group", "body": [{"blevel": 6, "type": "bullet", "indent": 4, "text": ["2D ", {"type": "code", "text": [".rat"]}, " texture tiles"], "extent": [12054, 12084]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["3D ", {"type": "code", "text": [".i3d"]}, " texture tiles"], "extent": [12084, 12114]}, {"blevel": 6, "type": "bullet", "indent": 4, "text": ["3D ", {"type": "code", "text": [".pc"]}, " point cloud pages (when not preloaded into memory)"], "extent": [12114, 12181]}], "container": true}, {"type": "para", "indent": 4, "text": ["Note:  This value is only used for off-line rendering, not IPR."], "extent": [12181, 12250]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 3, "id": "driver_tab", "container": true, "type": "h", "indent": 4, "text": ["Driver"], "extent": [27091, 27123], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Cancel Render if Missing Texture is Discovered"], "extent": [27123, 27176], "body": [{"type": "para", "indent": 4, "text": ["Turning on this option will cause Karma to stop the render with an error if it encounters a missing texture map."], "extent": [1538, 1656]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Cancel Render if No Working GPU Devices are Discovered"], "extent": [27251, 27311], "body": [{"type": "para", "indent": 4, "text": ["Turning on this option will cause Karma to stop the render with an error if no working gpu devices are discovered."], "extent": [1766, 1886]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}, {"level": 3, "id": "component_labels_tab", "container": true, "type": "h", "indent": 4, "text": ["Component Labels"], "extent": [27383, 27435], "body": [{"type": "parameters_item_group", "body": [{"type": "parameters_item", "indent": 4, "text": ["Export Componetents"], "extent": [27435, 27461], "body": [{"type": "para", "indent": 4, "text": ["A whitespace-separated list of shading component names that will be\n    computed for export. If you have defined new component labels in your\n    materials, these can be added to the list so that they are exported for\n    per-component export planes. If you are not using some components, remove\n    them from the list to improve render efficiency."], "extent": [3500, 3854]}, {"type": "para", "indent": 4, "text": ["PBR light exports assume that this list is complete - that is, all\n    components created by shaders are listed. If there are unlisted components,\n    light exports may be missing illumination from these components."], "extent": [3854, 4075]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Diffuse Components"], "extent": [27533, 27557], "body": [{"type": "para", "indent": 4, "text": ["A space-separated list of component types that will behave like diffuse\n    bounces.  This will affect which reflection scope is used based on the ray\n    type and also which bounce limit to use.  Uncategorized component types are\n    assumed to be reflections."], "extent": [4161, 4428]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Refract Components"], "extent": [27630, 27654], "body": [{"type": "para", "indent": 4, "text": ["A space-separated list of component types that will behave like refract\n    bounces.  This will affect which reflection scope is used based on the ray\n    type and also which bounce limit to use.  Uncategorized component types are\n    assumed to be reflections."], "extent": [4514, 4781]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["Volume Components"], "extent": [27727, 27750], "body": [{"type": "para", "indent": 4, "text": ["A space-separated list of component types that will behave like volume\n    bounces.  This will affect which reflection scope is used based on the ray\n    type and also which bounce limit to use.  Uncategorized component types are\n    assumed to be reflections."], "extent": [4865, 5131]}], "container": true, "role": "item"}, {"type": "parameters_item", "indent": 4, "text": ["SSS Components"], "extent": [27822, 27842], "body": [{"type": "para", "indent": 4, "text": ["A space-separated list of component types that will behave like subsurface\n    scatter bounces.  This will affect which reflection scope is used based on\n    the ray type and also which bounce limit to use.  Uncategorized component\n    types are assumed to be reflections."], "extent": [5209, 5487]}], "container": true, "role": "item"}], "container": true, "role": "item_group"}]}]}], "text": "Parameters"}, {"level": 1, "id": "related", "container": true, "type": "related_section", "indent": 0, "role": "section", "extent": [27912, 27921], "body": [{"type": "bullet_group", "body": [{"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/lop/additionalrendervars", "type": "link", "text": "", "fullpath": "/nodes/lop/additionalrendervars.html"}], "extent": [27921, 27956]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/lop/karma", "type": "link", "text": "", "fullpath": "/nodes/lop/karma.html"}], "extent": [27956, 27975]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/lop/karmastandardrendervars", "type": "link", "text": "", "fullpath": "/nodes/lop/karmastandardrendervars.html"}], "extent": [27975, 28012]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/lop/renderproduct", "type": "link", "text": "", "fullpath": "/nodes/lop/renderproduct.html"}], "extent": [28012, 28039]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/lop/rendersettings", "type": "link", "text": "", "fullpath": "/nodes/lop/rendersettings.html"}], "extent": [28039, 28067]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": "Node", "value": "/nodes/lop/rendervar", "type": "link", "text": "", "fullpath": "/nodes/lop/rendervar.html"}], "extent": [28067, 28090]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": null, "value": "/render/lpe", "type": "link", "text": ["Light Path Expressions"], "fullpath": "/render/lpe.html"}], "extent": [28090, 28129]}, {"blevel": 2, "type": "bullet", "indent": 0, "text": [{"scheme": null, "value": "/io/ocio", "type": "link", "text": ["OCIO"], "fullpath": "/io/ocio.html"}], "extent": [28129, 28148]}], "container": true}], "text": "Related"}], "title": ["Karma Render Properties"], "summary": ["Configure Render Properties for Karma."], "included": ["/nodes/lop/_primpattern", "/nodes/lop/_sampling", "/nodes/lop/_simple_prims", "/nodes/lop/karmastandardrendervars", "/nodes/lop/rendergeometrysettings", "/nodes/lop/renderproduct", "/nodes/lop/rendersettings", "/nodes/lop/rendervar", "/props/karma"]}